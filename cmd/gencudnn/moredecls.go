package main

/* generated by parse.py. DO NOT EDIT */
var inputParams = map[string][]string{
	"cudnnActivationForward":                                   {"handle", "activationDesc", "alpha", "beta", "xDesc", "x", "yDesc"},
	"cudnnAddTensor":                                           {"handle", "alpha", "beta", "aDesc", "A", "cDesc"},
	"cudnnBatchNormalizationForwardInference":                  {"handle", "mode", "alpha", "beta", "xDesc", "yDesc", "*x", "*y", "bnScaleBiasMeanVarDesc", "bnScale", "bnBias", "estimatedMean", "estimatedVariance", "epsilon"},
	"cudnnCreateActivationDescriptor":                          {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateAlgorithmDescriptor":                           {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateAlgorithmPerformance":                          {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateDropoutDescriptor":                             {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateFilterDescriptor":                              {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateLRNDescriptor":                                 {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreatePoolingDescriptor":                             {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateReduceTensorDescriptor":                        {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_BAD_PARAM", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateSpatialTransformerDescriptor":                  {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateTensorDescriptor":                              {"tensorDesc"},
	"cudnnDeriveBNTensorDescriptor":                            {"xDesc", "mode"},
	"cudnnDeriveNormTensorDescriptor":                          {"xDesc", "mode"},
	"cudnnDestroy":                                             {"handle"},
	"cudnnDestroyActivationDescriptor":                         {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyAlgorithmDescriptor":                          {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyAlgorithmPerformance":                         {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyDropoutDescriptor":                            {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyFilterDescriptor":                             {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyLRNDescriptor":                                {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyOpTensorDescriptor":                           {"opTensorDesc"},
	"cudnnDestroyPoolingDescriptor":                            {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyReduceTensorDescriptor":                       {"tensorDesc"},
	"cudnnDestroySpatialTransformerDescriptor":                 {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyTensorDescriptor":                             {"tensorDesc"},
	"cudnnDestroyTensorTransformDescriptor":                    {"transformDesc"},
	"cudnnDivisiveNormalizationForward":                        {"handle", "normDesc", "divNormMode", "alpha", "beta", "xDesc", "yDesc", "x", "means"},
	"cudnnDropoutForward":                                      {"handle", "dropoutDesc", "xDesc", "x", "yDesc", "reserveSpaceSizeInBytes"},
	"cudnnDropoutGetReserveSpaceSize":                          {"xDesc"},
	"cudnnDropoutGetStatesSize":                                {"handle"},
	"cudnnGetActivationDescriptor":                             {"activationDesc"},
	"cudnnGetAlgorithmDescriptor":                              {"algorithmDesc", "algorithm"},
	"cudnnGetAlgorithmSpaceSize":                               {"handle", "algoDesc"},
	"cudnnGetDropoutDescriptor":                                {"dropoutDesc", "handle"},
	"cudnnGetErrorString":                                      {"status"},
	"cudnnGetFilter4dDescriptor":                               {"filterDesc"},
	"cudnnGetFilterNdDescriptor":                               {"wDesc", "nbDimsRequested"},
	"cudnnGetFilterSizeInBytes":                                {"filterDesc"},
	"cudnnGetOpTensorDescriptor":                               {"opTensorDesc"},
	"cudnnGetPooling2dDescriptor":                              {"poolingDesc"},
	"cudnnGetPooling2dForwardOutputDim":                        {"poolingDesc", "inputDesc"},
	"cudnnGetPoolingNdDescriptor":                              {"poolingDesc", "nbDimsRequested", "maxpoolingNanOpt"},
	"cudnnGetPoolingNdForwardOutputDim":                        {"poolingDesc", "inputDesc", "nbDims"},
	"cudnnGetProperty":                                         {"type"},
	"cudnnGetReduceTensorDescriptor":                           {"reduceTensorDesc", "reduceTensorNanOpt"},
	"cudnnGetReductionIndicesSize":                             {"handle", "reduceDesc", "aDesc", "cDesc"},
	"cudnnGetReductionWorkspaceSize":                           {"handle", "reduceDesc", "aDesc", "cDesc"},
	"cudnnGetStream":                                           {"handle"},
	"cudnnGetTensor4dDescriptor":                               {"tensorDesc"},
	"cudnnGetTensorNdDescriptor":                               {"tensorDesc", "nbDimsRequested"},
	"cudnnGetTensorSizeInBytes":                                {"tensorDesc"},
	"cudnnGetTensorTransformDescriptor":                        {"transformDesc"},
	"cudnnInitTransformDest":                                   {"transformDesc", "srcDesc"},
	"cudnnLRNCrossChannelForward":                              {"handle", "normDesc", "lrnMode", "alpha", "beta", "xDesc", "yDesc", "x"},
	"cudnnNormalizationForwardInference":                       {"handle", "mode", "normOps", "algo", "alpha", "beta", "xDesc", "yDesc", "*x", "zDesc", "*z", "normScaleBiasDesc", "normScale", "normBias", "normMeanVarDesc", "estimatedMean", "estimatedVariance", "activationDesc", "epsilon", "groutCnt"},
	"cudnnOpsInferVersionCheck":                                {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_VERSION_MISMATCH"},
	"cudnnOpTensor":                                            {"handle", "opTensorDesc", "alpha1", "alpha2", "beta", "aDesc", "bDesc", "cDesc", "A", "B"},
	"cudnnPoolingForward":                                      {"handle", "poolingDesc", "alpha", "beta", "xDesc", "x", "yDesc"},
	"cudnnQueryRuntimeError":                                   {"handle", "mode"},
	"cudnnReduceTensor":                                        {"handle", "reduceTensorDesc", "indicesSizeInBytes", "workspace", "workspaceSizeInBytes", "alpha", "beta", "aDesc", "cDesc", "A"},
	"cudnnRestoreAlgorithm":                                    {"handle", "algoDesc", "algoSpace", "algoSpaceSizeInBytes"},
	"cudnnRestoreDropoutDescriptor":                            {"handle", "dropout", "states", "stateSizeInBytes", "seed"},
	"cudnnSaveAlgorithm":                                       {"handle", "algoDesc", "algoSpace", "algoSpaceSizeInBytes"},
	"cudnnScaleTensor":                                         {"handle", "yDesc", "alpha"},
	"cudnnSetActivationDescriptor":                             {"mode", "reluNanOpt", "coef"},
	"cudnnSetAlgorithmDescriptor":                              {"algorithm"},
	"cudnnSetAlgorithmPerformance":                             {"algoDesc", "status", "time", "memory"},
	"cudnnSetCallback":                                         {"mask", "udata", "fptr"},
	"cudnnSetDropoutDescriptor":                                {"handle", "dropout", "stateSizeInBytes", "seed"},
	"cudnnSetFilter4dDescriptor":                               {"datatype", "format", "k", "c", "h", "w"},
	"cudnnSetFilterNdDescriptor":                               {"datatype", "format", "nbDims", "filterDimA"},
	"cudnnSetLRNDescriptor":                                    {"lrnN", "lrnAlpha", "lrnBeta", "lrnK"},
	"cudnnSetOpTensorDescriptor":                               {"opTensorOp", "opTensorCompType", "opTensorNanOpt"},
	"cudnnSetPooling2dDescriptor":                              {"mode", "maxpoolingNanOpt", "windowHeight", "windowWidth", "verticalPadding", "horizontalPadding", "verticalStride", "horizontalStride"},
	"cudnnSetPoolingNdDescriptor":                              {"mode", "maxpoolingNanOpt", "nbDims", "windowDimA", "paddingA", "strideA"},
	"cudnnSetReduceTensorDescriptor":                           {"reduceTensorOp", "reduceTensorCompType", "reduceTensorNanOpt", "reduceTensorIndices", "reduceTensorIndicesType"},
	"cudnnSetSpatialTransformerNdDescriptor":                   {"samplerType", "dataType", "nbDims", "dimA"},
	"cudnnSetStream":                                           {"handle", "streamID"},
	"cudnnSetTensor":                                           {"handle", "yDesc", "valuePtr"},
	"cudnnSetTensor4dDescriptor":                               {"format", "datatype", "n", "c", "h", "w"},
	"cudnnSetTensor4dDescriptorEx":                             {"datatype", "n", "c", "h", "w", "nStride", "cStride", "hStride", "wStride"},
	"cudnnSetTensorNdDescriptor":                               {"datatype", "nbDims", "dimA", "strideA"},
	"cudnnSetTensorNdDescriptorEx":                             {"format", "dataType", "nbDims", "dimA"},
	"cudnnSetTensorTransformDescriptor":                        {"nbDims", "destFormat", "padBeforeA[]", "padAfterA[]", "foldA[]", "direction"},
	"cudnnSoftmaxForward":                                      {"handle", "algorithm", "mode", "alpha", "beta", "xDesc", "x", "yDesc"},
	"cudnnSpatialTfGridGeneratorForward":                       {"handle", "stDesc", "theta"},
	"cudnnSpatialTfSamplerForward":                             {"handle", "stDesc", "alpha", "beta", "xDesc", "x", "grid", "yDesc"},
	"cudnnTransformFilter":                                     {"handle", "transDesc", "alpha", "beta", "srcDesc", "destDesc", "srcData", "destData"},
	"cudnnTransformTensor":                                     {"handle", "alpha", "beta", "xDesc", "x", "yDesc"},
	"cudnnTransformTensorEx":                                   {"handle", "transDesc", "alpha", "beta", "srcDesc", "destDesc", "srcData", "destData"},
	"cudnnActivationBackward":                                  {"handle", "activationDesc", "alpha", "beta", "yDesc", "y", "dyDesc", "dy", "xDesc", "x", "dxDesc"},
	"cudnnBatchNormalizationBackward":                          {"handle", "mode", "*alphaDataDiff", "*betaDataDiff", "*alphaParamDiff", "*betaParamDiff", "xDesc", "dxDesc", "dyDesc", "*x", "*dy", "*dx", "bnScaleBiasDiffDesc", "*bnScale", "epsilon", "*savedMean", "*savedInvVariance"},
	"cudnnBatchNormalizationBackwardEx":                        {"handle", "mode", "bnOps", "*alphaDataDiff", "*betaDataDiff", "*alphaParamDiff", "*betaParamDiff", "xDesc", "*x", "yDesc", "*yData", "dyDesc", "*dyData", "dBnScaleBiasDesc", "*bnScaleData", "*bnBiasData", "*dBnScaleData", "dBnBiasData", "epsilon", "*savedMean", "*savedInvVariance", "activationDesc", "workspace", "workSpaceSizeInBytes", "*reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnBatchNormalizationForwardTraining":                   {"handle", "mode", "alpha", "beta", "xDesc", "yDesc", "*x", "*y", "bnScaleBiasMeanVarDesc", "bnScale", "bnBias", "exponentialAverageFactor", "epsilon"},
	"cudnnBatchNormalizationForwardTrainingEx":                 {"handle", "mode", "bnOps", "*alpha", "*beta", "xDesc", "*xData", "zDesc", "*zData", "yDesc", "*yData", "bnScaleBiasMeanVarDesc", "*bnScaleData", "*bnBiasData", "exponentialAverageFactor", "epsilon", "activationDesc", "*workspace", "workSpaceSizeInBytes", "*reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnDivisiveNormalizationBackward":                       {"handle", "normDesc", "mode", "alpha", "beta", "xDesc", "x", "means", "dy", "dxDesc"},
	"cudnnDropoutBackward":                                     {"handle", "dropoutDesc", "dyDesc", "dy", "dxDesc", "reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnGetBatchNormalizationBackwardExWorkspaceSize":        {"handle", "mode", "bnOps", "xDesc", "yDesc", "dyDesc", "dzDesc", "dxDesc", "dBnScaleBiasDesc", "activationDesc"},
	"cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize": {"handle", "mode", "bnOps", "xDesc", "zDesc", "yDesc", "bnScaleBiasMeanVarDesc", "activationDesc"},
	"cudnnGetBatchNormalizationTrainingExReserveSpaceSize":     {"handle", "mode", "bnOps", "xDesc", "activationDesc"},
	"cudnnGetNormalizationBackwardWorkspaceSize":               {"handle", "mode", "normOps", "algo", "xDesc", "yDesc", "dyDesc", "dzDesc", "dxDesc", "dNormScaleBiasDesc", "activationDesc", "normMeanVarDesc", "groutCnt"},
	"cudnnGetNormalizationForwardTrainingWorkspaceSize":        {"handle", "mode", "normOps", "algo", "xDesc", "zDesc", "yDesc", "normScaleBiasDesc", "activationDesc", "normMeanVarDesc", "groutCnt"},
	"cudnnGetNormalizationTrainingReserveSpaceSize":            {"handle", "mode", "normOps", "algo", "xDesc", "activationDesc", "groutCnt"},
	"cudnnLRNCrossChannelBackward":                             {"handle", "normDesc", "lrnMode", "alpha", "beta", "yDesc", "y", "dyDesc", "dy", "xDesc", "x"},
	"cudnnNormalizationBackward":                               {"dNormScaleBiasDesc", "*normScaleData", "*normBiasData", "*dNormScaleData", "dNormBiasData", "epsilon", "normMeanVarDesc", "*savedMean", "*savedInvVariance", "activationDesc", "workspace", "workSpaceSizeInBytes", "*reserveSpace", "reserveSpaceSizeInBytes", "groutCnt"},
	"cudnnNormalizationForwardTraining":                        {"handle", "mode", "normOps", "algo", "*alpha", "*beta", "xDesc", "yDesc", "*xData", "zDesc", "*zData", "normScaleBiasDesc", "normScale", "normBias", "exponentialAverageFactor", "normMeanVarDesc", "epsilon", "activationDesc", "*workspace", "workSpaceSizeInBytes", "*reserveSpace", "reserveSpaceSizeInBytes", "groutCnt"},
	"cudnnOpsTrainVersionCheck":                                {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_VERSION_MISMATCH"},
	"cudnnPoolingBackward":                                     {"handle", "poolingDesc", "alpha", "beta", "yDesc", "y", "dyDesc", "dy", "xDesc", "x", "dxDesc"},
	"cudnnSoftmaxBackward":                                     {"handle", "algorithm", "mode", "alpha", "beta", "yDesc", "y", "dyDesc", "dy", "dxDesc"},
	"cudnnSpatialTfGridGeneratorBackward":                      {"handle", "stDesc", "dgrid"},
	"cudnnSpatialTfSamplerBackward":                            {"handle", "stDesc", "alpha", "beta", "xDesc", "x", "dxDesc", "alphaDgrid", "betaDgrid", "dyDesc", "dy", "grid"},
	"cudnnBackendCreateDescriptor":                             {"descriptorType", "descriptor"},
	"cudnnBackendDestroyDescriptor":                            {"descriptor"},
	"cudnnBackendExecute":                                      {"executionPlan", "variantPack"},
	"cudnnBackendFinalize":                                     {"descriptor"},
	"cudnnBackendGetAttribute":                                 {"descriptor", "attributeName", "attributeType", "requestedElementCount", "elementCount", "arrayOfElements"},
	"cudnnBackendInitialize":                                   {"descriptor", "descriptorType", "sizeInBytes"},
	"cudnnBackendSetAttribute":                                 {"descriptor", "attributeName", "attributeType", "elementCount", "arrayOfElements"},
	"cudnnConvolutionBackwardData":                             {"handle", "alpha", "beta", "wDesc", "w", "dyDesc", "dy", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "dxDesc"},
	"cudnnConvolutionBiasActivationForward":                    {"handle", "alpha1", "alpha2", "xDesc", "x", "wDesc", "w", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "zDesc", "z", "biasDesc", "bias", "activationDesc", "yDesc"},
	"cudnnConvolutionForward":                                  {"handle", "alpha", "beta", "xDesc", "x", "wDesc", "w", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "yDesc"},
	"cudnnCreateConvolutionDescriptor":                         {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnDestroyConvolutionDescriptor":                        {"CUDNN_STATUS_SUCCESS"},
	"cudnnFindConvolutionBackwardDataAlgorithm":                {"handle", "wDesc", "dyDesc", "convDesc", "dxDesc", "requestedAlgoCount"},
	"cudnnFindConvolutionBackwardDataAlgorithmEx":              {"handle", "wDesc", "w", "dyDesc", "dy", "convDesc", "dxDesc", "requestedAlgoCount", "workSpace", "workSpaceSizeInBytes"},
	"cudnnFindConvolutionForwardAlgorithm":                     {"handle", "xDesc", "wDesc", "convDesc", "yDesc", "requestedAlgoCount"},
	"cudnnFindConvolutionForwardAlgorithmEx":                   {"handle", "xDesc", "x", "wDesc", "w", "convDesc", "yDesc", "requestedAlgoCount", "workSpace", "workSpaceSizeInBytes"},
	"cudnnGetConvolution2dForwardOutputDim":                    {"convDesc", "inputTensorDesc", "filterDesc"},
	"cudnnGetConvolutionBackwardDataAlgorithmMaxCount":         {"handle"},
	"cudnnGetConvolutionBackwardDataAlgorithm_v7":              {"handle", "wDesc", "dyDesc", "convDesc", "dxDesc", "requestedAlgoCount"},
	"cudnnGetConvolutionBackwardDataWorkspaceSize":             {"handle", "wDesc", "dyDesc", "convDesc", "dxDesc", "algo"},
	"cudnnGetConvolutionForwardAlgorithmMaxCount":              {"handle"},
	"cudnnGetConvolutionForwardAlgorithm_v7":                   {"handle", "xDesc", "wDesc", "convDesc", "yDesc", "requestedAlgoCount"},
	"cudnnGetConvolutionForwardWorkspaceSize":                  {"handle", "xDesc", "wDesc", "convDesc", "yDesc", "algo"},
	"cudnnGetConvolutionGroupCount":                            {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_BAD_PARAM"},
	"cudnnGetConvolutionMathType":                              {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_BAD_PARAM"},
	"cudnnGetConvolutionNdDescriptor":                          {"arrayLengthRequested"},
	"cudnnGetConvolutionNdForwardOutputDim":                    {"convDesc", "inputTensorDesc", "filterDesc", "nbDims"},
	"cudnnGetConvolutionReorderType":                           {"convDesc"},
	"cudnnGetFoldedConvBackwardDataDescriptors":                {"handle", "filterDesc", "diffDesc", "convDesc", "gradDesc", "transformFormat"},
	"cudnnIm2Col":                                              {"handle", "srcDesc", "srcData", "filterDesc", "convDesc"},
	"cudnnReorderFilterAndBias":                                {"filterDesc", "reorderType", "filterData", "reorderedFilterData", "reorderBias", "biasData", "reorderedBiasData"},
	"cudnnSetConvolution2dDescriptor":                          {"pad_h", "pad_w", "u", "v", "dilation_h", "dilation_w", "mode", "computeType"},
	"cudnnSetConvolutionGroupCount":                            {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_BAD_PARAM"},
	"cudnnSetConvolutionMathType":                              {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_BAD_PARAM"},
	"cudnnSetConvolutionNdDescriptor":                          {"arrayLength", "padA", "filterStrideA", "dilationA", "mode", "datatype"},
	"cudnnSetConvolutionReorderType":                           {"convDesc", "reorderType"},
	"cudnnConvolutionBackwardBias":                             {"handle", "alpha", "beta", "dyDesc", "dy", "dbDesc"},
	"cudnnConvolutionBackwardFilter":                           {"handle", "alpha", "beta", "xDesc", "x", "dyDesc", "dy", "convDesc", "algo", "workSpace", "workSpaceSizeInBytes", "dwDesc"},
	"cudnnCreateFusedOpsConstParamPack":                        {"constPack", "ops"},
	"cudnnCreateFusedOpsPlan":                                  {"plan", "ops"},
	"cudnnCreateFusedOpsVariantParamPack":                      {"varPack", "ops"},
	"cudnnDestroyFusedOpsConstParamPack":                       {"constPack"},
	"cudnnDestroyFusedOpsPlan":                                 {"plan"},
	"cudnnDestroyFusedOpsVariantParamPack":                     {"varPack"},
	"cudnnFindConvolutionBackwardFilterAlgorithm":              {"handle", "xDesc", "dyDesc", "convDesc", "dwDesc", "requestedAlgoCount"},
	"cudnnFindConvolutionBackwardFilterAlgorithmEx":            {"handle", "xDesc", "x", "dyDesc", "dy", "convDesc", "dwDesc", "requestedAlgoCount", "workSpace", "workSpaceSizeInBytes"},
	"cudnnFusedOpsExecute":                                     {"handle", "plan", "varPack"},
	"cudnnGetConvolutionBackwardFilterAlgorithmMaxCount":       {"handle"},
	"cudnnGetConvolutionBackwardFilterAlgorithm_v7":            {"handle", "xDesc", "dyDesc", "convDesc", "dwDesc", "requestedAlgoCount"},
	"cudnnGetConvolutionBackwardFilterWorkspaceSize":           {"handle", "xDesc", "dyDesc", "convDesc", "dwDesc", "algo"},
	"cudnnGetFusedOpsConstParamPackAttribute":                  {"constPack", "paramLabel", "param"},
	"cudnnGetFusedOpsVariantParamPackAttribute":                {"varPack", "paramLabel"},
	"cudnnMakeFusedOpsPlan":                                    {"handle", "plan", "constPack"},
	"cudnnSetFusedOpsConstParamPackAttribute":                  {"constPack", "paramLabel", "param"},
	"cudnnSetFusedOpsVariantParamPackAttribute":                {"varPack", "paramLabel", "ptr"},
	"cudnnAdvInferVersionCheck":                                {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_VERSION_MISMATCH"},
	"cudnnBuildRNNDynamic":                                     {"handle", "rnnDesc", "miniBatch"},
	"cudnnCreatePersistentRNNPlan":                             {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_MAPPING_ERROR", "CUDNN_STATUS_ALLOC_FAILED", "CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING", "CUDNN_STATUS_NOT_SUPPORTED"},
	"cudnnCreateRNNDataDescriptor":                             {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_BAD_PARAM", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnCreateRNNDescriptor":                                 {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_ALLOC_FAILED"},
	"cudnnDestroyPersistentRNNPlan":                            {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyRNNDataDescriptor":                            {"CUDNN_STATUS_SUCCESS"},
	"cudnnDestroyRNNDescriptor":                                {"CUDNN_STATUS_SUCCESS"},
	"cudnnFindRNNForwardInferenceAlgorithmEx":                  {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes"},
	"cudnnGetAttnDescriptor":                                   {"attnDesc"},
	"cudnnGetMultiHeadAttnBuffers":                             {"handle", "attnDesc"},
	"cudnnGetMultiHeadAttnWeights":                             {"handle", "attnDesc", "wKind", "weightSizeInBytes", "weights"},
	"cudnnGetRNNBiasMode":                                      {"rnnDesc"},
	"cudnnGetRNNDataDescriptor":                                {"RNNDataDesc", "arrayLengthRequested"},
	"cudnnGetRNNDescriptor_v6":                                 {"handle", "rnnDesc"},
	"cudnnGetRNNDescriptor_v8":                                 {"rnnDesc"},
	"cudnnGetRNNLinLayerBiasParams":                            {"handle", "rnnDesc", "pseudoLayer", "xDesc", "wDesc", "w", "linLayerID"},
	"cudnnGetRNNLinLayerMatrixParams":                          {"handle", "rnnDesc", "pseudoLayer", "xDesc", "wDesc", "w", "linLayerID"},
	"cudnnGetRNNMatrixMathType":                                {"rnnDesc"},
	"cudnnGetRNNPaddingMode":                                   {"*paddingMode"},
	"cudnnGetRNNParamsSize":                                    {"handle", "rnnDesc", "xDesc", "dataType"},
	"cudnnGetRNNProjectionLayers":                              {"handle", "rnnDesc"},
	"cudnnGetRNNTempSpaceSizes":                                {"handle", "rnnDesc", "fMode", "xDesc"},
	"cudnnGetRNNWeightParams":                                  {"handle", "rnnDesc", "pseudoLayer", "weightSpaceSize", "weightSpace", "linLayerID"},
	"cudnnGetRNNWeightSpaceSize":                               {"handle", "rnnDesc"},
	"cudnnGetRNNWorkspaceSize":                                 {"handle", "rnnDesc", "seqLength", "xDesc"},
	"cudnnMultiHeadAttnForward":                                {"handle", "attnDesc", "currIdx", "loWinIdx[]", "hiWinIdx[]", "devSeqLengthsQO[]", "devSeqLengthsKV[]", "qDesc", "queries", "residuals", "kDesc", "keys", "vDesc", "values", "oDesc", "weightSizeInBytes", "weights", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnRNNForward":                                          {"handle", "rnnDesc", "fwdMode", "devSeqLengths", "xDesc", "x", "yDesc", "hDesc", "hx", "cDesc", "cx", "weightSpaceSize", "weightSpace", "workSpaceSize", "reserveSpaceSize"},
	"cudnnRNNForwardInference":                                 {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "workspace", "workSpaceSizeInBytes"},
	"cudnnRNNForwardInferenceEx":                               {"handle", "rnnDesc", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "kDesc", "keys", "cDesc", "cAttn", "iDesc", "iAttn", "qDesc", "queries", "workspace", "workSpaceSizeInBytes"},
	"cudnnRNNGetClip_v8":                                       {"rnnDesc"},
	"cudnnRNNSetClip":                                          {"clipMode", "lclip", "rclip", "clipNanOpt"},
	"cudnnRNNSetClip_v8":                                       {"rnnDesc", "clipMode", "clipNanOpt", "lclip", "rclip"},
	"cudnnSetAttnDescriptor":                                   {"attnMode", "nHeads", "smScaler", "dataType", "computePrec", "mathType", "attnDropoutDesc", "postDropoutDesc", "qSize", "kSize", "vSize", "qProjSize", "kProjSize", "vProjSize", "oProjSize", "qoMaxSeqLength", "kvMaxSeqLength", "maxBatchSize", "maxBeamSize"},
	"cudnnSetPersistentRNNPlan":                                {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_BAD_PARAM"},
	"cudnnSetRNNBiasMode":                                      {"biasMode"},
	"cudnnSetRNNDataDescriptor":                                {"dataType", "layout", "maxSeqLength", "batchSize", "vectorSize", "seqLengthArray", "paddingFill"},
	"cudnnSetRNNDescriptor_v6":                                 {"handle", "hiddenSize", "numLayers", "dropoutDesc", "inputMode", "direction", "mode", "algo", "mathPrec"},
	"cudnnSetRNNDescriptor_v8":                                 {"rnnDesc", "algo", "cellMode", "biasMode", "dirMode", "inputMode", "dataType", "mathPrec", "mathType", "inputSize", "hiddenSize", "projSize", "numLayers", "dropoutDesc", "auxFlags"},
	"cudnnSetRNNMatrixMathType":                                {"rnnDesc", "mType"},
	"cudnnSetRNNPaddingMode":                                   {"paddingMode"},
	"cudnnSetRNNProjectionLayers":                              {"handle", "rnnDesc", "recProjSize", "outProjSize"},
	"cudnnAdvTrainVersionCheck":                                {"CUDNN_STATUS_SUCCESS", "CUDNN_STATUS_VERSION_MISMATCH"},
	"cudnnCTCLoss":                                             {"handle", "probsDesc", "probs", "hostLabels", "hostLabelLengths", "hostInputLengths", "gradientsDesc", "algo", "ctcLossDesc", "workspace", "sizeInBytes"},
	"cudnnCTCLoss_v8":                                          {"handle", "algo", "ctcLossDesc", "probsDesc", "probs", "labels", "labelLengths", "inputLengths", "gradientsDesc", "workspace", "sizeInBytes"},
	"cudnnDestroyCTCLossDescriptor":                            {"ctcLossDesc"},
	"cudnnFindRNNBackwardDataAlgorithmEx":                      {"handle", "rnnDesc", "seqLength", "yDesc", "y", "dyDesc", "dy", "dhyDesc", "dhy", "dcyDesc", "dcy", "wDesc", "w", "hxDesc", "hx", "cxDesc", "cx", "dxDesc", "dhxDesc", "dcxDesc", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnFindRNNBackwardWeightsAlgorithmEx":                   {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "yDesc", "y", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes", "dwDesc", "reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnFindRNNForwardTrainingAlgorithmEx":                   {"handle", "rnnDesc", "xDesc", "seqLength", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "findIntensity", "requestedAlgoCount", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnGetCTCLossDescriptor":                                {"ctcLossDesc"},
	"cudnnGetCTCLossDescriptorEx":                              {"ctcLossDesc"},
	"cudnnGetCTCLossDescriptor_v8":                             {"ctcLossDesc"},
	"cudnnGetCTCLossWorkspaceSize":                             {"handle", "probsDesc", "gradientsDesc", "labels", "labelLengths", "inputLengths", "algo", "ctcLossDesc"},
	"cudnnGetCTCLossWorkspaceSize_v8":                          {"handle", "algo", "ctcLossDesc", "probsDesc", "gradientsDesc"},
	"cudnnGetRNNTrainingReserveSize":                           {"handle", "rnnDesc", "seqLength", "xDesc"},
	"cudnnMultiHeadAttnBackwardData":                           {"handle", "attnDesc", "loWinIdx[]", "hiWinIdx[]", "devSeqLengthsDQDO[]", "devSeqLengthsDKDV[]", "doDesc", "dout", "dqDesc", "queries", "dkDesc", "keys", "dvDesc", "values", "weightSizeInBytes", "weights", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnMultiHeadAttnBackwardWeights":                        {"handle", "attnDesc", "addGrad", "qDesc", "queries", "kDesc", "keys", "vDesc", "values", "doDesc", "dout", "weightSizeInBytes", "weights", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnRNNBackwardData":                                     {"handle", "rnnDesc", "seqLength", "yDesc", "y", "dyDesc", "dy", "dhyDesc", "dhy", "dcyDesc", "dcy", "wDesc", "w", "hxDesc", "hx", "cxDesc", "cx", "dxDesc", "dhxDesc", "dcxDesc", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnRNNBackwardData_v8":                                  {"handle", "rnnDesc", "devSeqLengths", "yDesc", "y", "dy", "xDesc", "hDesc", "hx", "dhy", "cDesc", "cx", "dcy", "weightSpaceSize", "weightSpace", "workSpaceSize", "reserveSpaceSize"},
	"cudnnRNNBackwardDataEx":                                   {"handle", "rnnDesc", "yDesc", "y", "dyDesc", "dy", "dhyDesc", "dhy", "dcyDesc", "dcy", "wDesc", "w", "hxDesc", "hx", "cxDesc", "cx", "dxDesc", "dhxDesc", "dcxDesc", "dkDesc", "dkeys", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnRNNBackwardWeights":                                  {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "yDesc", "y", "workspace", "workSpaceSizeInBytes", "dwDesc", "reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnRNNBackwardWeights_v8":                               {"handle", "rnnDesc", "addGrad", "devSeqLengths", "xDesc", "x", "hDesc", "hx", "yDesc", "weightSpaceSize", "workSpaceSize", "reserveSpaceSize"},
	"cudnnRNNBackwardWeightsEx":                                {"handle", "rnnDesc", "xDesc", "x", "hxDesc", "hx", "yDesc", "y", "workspace", "workSpaceSizeInBytes", "dwDesc", "reserveSpace", "reserveSpaceSizeInBytes"},
	"cudnnRNNForwardTraining":                                  {"handle", "rnnDesc", "seqLength", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnRNNForwardTrainingEx":                                {"handle", "rnnDesc", "xDesc", "x", "hxDesc", "hx", "cxDesc", "cx", "wDesc", "w", "yDesc", "hyDesc", "cyDesc", "kDesc", "keys", "cDesc", "cAttn", "iDesc", "iAttn", "qDesc", "queries", "workspace", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnSetCTCLossDescriptor":                                {"compType"},
	"cudnnSetCTCLossDescriptorEx":                              {"compType", "normMode", "gradMode"},
	"cudnnSetCTCLossDescriptor_v8":                             {"compType", "normMode", "gradMode", "maxLabelLength"},
}
var outputParams = map[string][]string{
	"cudnnActivationForward":                                   {"y"},
	"cudnnCreate":                                              {"handle"},
	"cudnnCreateOpTensorDescriptor":                            {"opTensorDesc"},
	"cudnnCreateTensorTransformDescriptor":                     {"transformDesc"},
	"cudnnDeriveBNTensorDescriptor":                            {"derivedBnDesc"},
	"cudnnDeriveNormTensorDescriptor":                          {"derivedNormScaleBiasDesc", "derivedNormMeanVarDesc"},
	"cudnnDivisiveNormalizationForward":                        {"y"},
	"cudnnDropoutForward":                                      {"y", "reserveSpace"},
	"cudnnDropoutGetReserveSpaceSize":                          {"sizeInBytes"},
	"cudnnDropoutGetStatesSize":                                {"sizeInBytes"},
	"cudnnGetActivationDescriptor":                             {"mode", "reluNanOpt", "coef"},
	"cudnnGetAlgorithmPerformance":                             {"algoDesc", "status", "timecoef", "memory"},
	"cudnnGetAlgorithmSpaceSize":                               {"algoSpaceSizeInBytes"},
	"cudnnGetCallback":                                         {"mask", "udata", "fptr"},
	"cudnnGetDropoutDescriptor":                                {"dropout", "states", "seed"},
	"cudnnGetFilter4dDescriptor":                               {"datatype", "format", "k", "c", "h", "w"},
	"cudnnGetFilterNdDescriptor":                               {"datatype", "format", "nbDims", "filterDimA"},
	"cudnnGetFilterSizeInBytes":                                {"size"},
	"cudnnGetLRNDescriptor":                                    {"normDesc", "lrnN", "lrnAlpha", "lrnBeta", "lrnK"},
	"cudnnGetOpTensorDescriptor":                               {"opTensorOp", "opTensorCompType", "opTensorNanOpt"},
	"cudnnGetPooling2dDescriptor":                              {"mode", "maxpoolingNanOpt", "windowHeight", "windowWidth", "verticalPadding", "horizontalPadding", "verticalStride", "horizontalStride"},
	"cudnnGetPooling2dForwardOutputDim":                        {"N", "C", "H", "W"},
	"cudnnGetPoolingNdDescriptor":                              {"mode", "nbDims", "windowDimA", "paddingA", "strideA"},
	"cudnnGetPoolingNdForwardOutputDim":                        {"outDimA"},
	"cudnnGetProperty":                                         {"value"},
	"cudnnGetReduceTensorDescriptor":                           {"reduceTensorOp", "reduceTensorCompType", "reduceTensorIndices", "reduceTensorIndicesType"},
	"cudnnGetReductionIndicesSize":                             {"sizeInBytes"},
	"cudnnGetReductionWorkspaceSize":                           {"sizeInBytes"},
	"cudnnGetStream":                                           {"streamID"},
	"cudnnGetTensor4dDescriptor":                               {"datatype", "n", "c", "h", "w", "nStride", "cStride", "hStride", "wStride"},
	"cudnnGetTensorNdDescriptor":                               {"datatype", "nbDims", "dimA", "strideA"},
	"cudnnGetTensorSizeInBytes":                                {"size"},
	"cudnnGetTensorTransformDescriptor":                        {"destFormat", "padBeforeA[]", "padAfterA[]", "foldA[]", "direction"},
	"cudnnInitTransformDest":                                   {"destDesc", "destSizeInBytes"},
	"cudnnLRNCrossChannelForward":                              {"y"},
	"cudnnNormalizationForwardInference":                       {"*y"},
	"cudnnPoolingForward":                                      {"y"},
	"cudnnQueryRuntimeError":                                   {"rstatus"},
	"cudnnReduceTensor":                                        {"indices"},
	"cudnnSetDropoutDescriptor":                                {"states"},
	"cudnnSetLRNDescriptor":                                    {"normDesc"},
	"cudnnSetOpTensorDescriptor":                               {"opTensorDesc"},
	"cudnnSetTensorNdDescriptorEx":                             {"tensorDesc"},
	"cudnnSetTensorTransformDescriptor":                        {"transformDesc"},
	"cudnnSoftmaxForward":                                      {"y"},
	"cudnnSpatialTfGridGeneratorForward":                       {"grid"},
	"cudnnSpatialTfSamplerForward":                             {"y"},
	"cudnnTransformTensor":                                     {"y"},
	"cudnnActivationBackward":                                  {"dx"},
	"cudnnBatchNormalizationBackward":                          {"resultBnScaleDiff", "resultBnBiasDiff"},
	"cudnnBatchNormalizationBackwardEx":                        {"dzDesc", "*dzData", "dxDesc", "*dxData"},
	"cudnnBatchNormalizationForwardTraining":                   {"resultSaveMean", "resultSaveInvVariance"},
	"cudnnBatchNormalizationForwardTrainingEx":                 {"*saveMean", "*saveInvVariance"},
	"cudnnDivisiveNormalizationBackward":                       {"dx", "dMeans"},
	"cudnnDropoutBackward":                                     {"dx"},
	"cudnnGetBatchNormalizationBackwardExWorkspaceSize":        {"*sizeInBytes"},
	"cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize": {"*sizeInBytes"},
	"cudnnGetBatchNormalizationTrainingExReserveSpaceSize":     {"*sizeInBytes"},
	"cudnnGetNormalizationBackwardWorkspaceSize":               {"*sizeInBytes"},
	"cudnnGetNormalizationForwardTrainingWorkspaceSize":        {"*sizeInBytes"},
	"cudnnGetNormalizationTrainingReserveSpaceSize":            {"*sizeInBytes"},
	"cudnnLRNCrossChannelBackward":                             {"dxDesc", "dx"},
	"cudnnNormalizationBackward":                               {"dzDesc", "*dzData", "dxDesc", "*dxData"},
	"cudnnNormalizationForwardTraining":                        {"*yData", "*resultSaveMean", "*resultSaveInvVariance"},
	"cudnnPoolingBackward":                                     {"dx"},
	"cudnnSoftmaxBackward":                                     {"dx"},
	"cudnnSpatialTfGridGeneratorBackward":                      {"dtheta"},
	"cudnnSpatialTfSamplerBackward":                            {"dx", "dgrid"},
	"cudnnFindConvolutionBackwardDataAlgorithm":                {"returnedAlgoCount", "perfResults"},
	"cudnnFindConvolutionBackwardDataAlgorithmEx":              {"returnedAlgoCount", "perfResults"},
	"cudnnFindConvolutionForwardAlgorithm":                     {"returnedAlgoCount", "perfResults"},
	"cudnnFindConvolutionForwardAlgorithmEx":                   {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolution2dDescriptor":                          {"pad_h", "pad_w", "u", "v", "dilation_h", "dilation_w", "mode", "computeType"},
	"cudnnGetConvolution2dForwardOutputDim":                    {"n", "c", "h", "w"},
	"cudnnGetConvolutionBackwardDataAlgorithmMaxCount":         {"count"},
	"cudnnGetConvolutionBackwardDataAlgorithm_v7":              {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionBackwardDataWorkspaceSize":             {"sizeInBytes"},
	"cudnnGetConvolutionForwardAlgorithmMaxCount":              {"count"},
	"cudnnGetConvolutionForwardAlgorithm_v7":                   {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionForwardWorkspaceSize":                  {"sizeInBytes"},
	"cudnnGetConvolutionNdDescriptor":                          {"arrayLength", "padA", "filterStrideA", "dilationA", "mode", "datatype"},
	"cudnnGetConvolutionNdForwardOutputDim":                    {"tensorOuputDimA"},
	"cudnnGetConvolutionReorderType":                           {"reorderType"},
	"cudnnGetFoldedConvBackwardDataDescriptors":                {"foldedFilterDesc", "paddedDiffDesc", "foldedConvDesc", "foldedGradDesc", "filterFoldTransDesc", "diffPadTransDesc", "gradFoldTransDesc", "gradUnfoldTransDesc"},
	"cudnnIm2Col":                                              {"colBuffer"},
	"cudnnConvolutionBackwardBias":                             {"db"},
	"cudnnFindConvolutionBackwardFilterAlgorithm":              {"returnedAlgoCount", "perfResults"},
	"cudnnFindConvolutionBackwardFilterAlgorithmEx":            {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionBackwardFilterAlgorithmMaxCount":       {"count"},
	"cudnnGetConvolutionBackwardFilterAlgorithm_v7":            {"returnedAlgoCount", "perfResults"},
	"cudnnGetConvolutionBackwardFilterWorkspaceSize":           {"sizeInBytes"},
	"cudnnGetFusedOpsVariantParamPackAttribute":                {"ptr"},
	"cudnnMakeFusedOpsPlan":                                    {"workspaceSizeInBytes"},
	"cudnnFindRNNForwardInferenceAlgorithmEx":                  {"y", "hy", "cy", "returnedAlgoCount", "perfResults"},
	"cudnnGetAttnDescriptor":                                   {"attnMode", "nHeads", "smScaler", "dataType", "computePrec", "mathType", "attnDropoutDesc", "postDropoutDesc", "qSize", "kSize", "vSize", "qProjSize", "kProjSize", "vProjSize", "oProjSize", "qoMaxSeqLength", "kvMaxSeqLength", "maxBatchSize", "maxBeamSize"},
	"cudnnGetMultiHeadAttnBuffers":                             {"weightSizeInBytes", "workSpaceSizeInBytes", "reserveSpaceSizeInBytes"},
	"cudnnGetMultiHeadAttnWeights":                             {"wDesc", "wAddr"},
	"cudnnGetRNNBiasMode":                                      {"*biasMode"},
	"cudnnGetRNNDataDescriptor":                                {"dataType", "layout", "maxSeqLength", "batchSize", "vectorSize", "seqLengthArray", "paddingFill"},
	"cudnnGetRNNDescriptor_v6":                                 {"hiddenSize", "numLayers", "dropoutDesc", "inputMode", "direction", "mode", "algo", "mathPrec"},
	"cudnnGetRNNDescriptor_v8":                                 {"algo", "cellMode", "biasMode", "dirMode", "inputMode", "dataType", "mathPrec", "mathType", "inputSize", "hiddenSize", "projSize", "numLayers", "dropoutDesc", "auxFlags"},
	"cudnnGetRNNLinLayerBiasParams":                            {"linLayerBiasDesc", "linLayerBias"},
	"cudnnGetRNNLinLayerMatrixParams":                          {"linLayerMatDesc", "linLayerMat"},
	"cudnnGetRNNMatrixMathType":                                {"mType"},
	"cudnnGetRNNParamsSize":                                    {"sizeInBytes"},
	"cudnnGetRNNProjectionLayers":                              {"recProjSize", "outProjSize"},
	"cudnnGetRNNTempSpaceSizes":                                {"workSpaceSize", "reserveSpaceSize"},
	"cudnnGetRNNWeightParams":                                  {"mDesc", "mAddr", "bDesc", "bAddr"},
	"cudnnGetRNNWeightSpaceSize":                               {"weightSpaceSize"},
	"cudnnGetRNNWorkspaceSize":                                 {"sizeInBytes"},
	"cudnnMultiHeadAttnForward":                                {"out"},
	"cudnnRNNForward":                                          {"y", "hy", "cy"},
	"cudnnRNNForwardInference":                                 {"y", "hy", "cy"},
	"cudnnRNNForwardInferenceEx":                               {"y", "hy", "cy"},
	"cudnnRNNGetClip":                                          {"*clipMode", "*lclip", "*rclip", "*clipNanOpt"},
	"cudnnRNNGetClip_v8":                                       {"clipMode", "clipNanOpt", "lclip", "rclip"},
	"cudnnSetAttnDescriptor":                                   {"attnDesc"},
	"cudnnCreateCTCLossDescriptor":                             {"ctcLossDesc"},
	"cudnnCTCLoss":                                             {"costs", "gradients"},
	"cudnnCTCLoss_v8":                                          {"costs", "gradients"},
	"cudnnFindRNNBackwardDataAlgorithmEx":                      {"dx", "dhx", "dcx", "returnedAlgoCount", "perfResults"},
	"cudnnFindRNNBackwardWeightsAlgorithmEx":                   {"returnedAlgoCount", "perfResults"},
	"cudnnFindRNNForwardTrainingAlgorithmEx":                   {"y", "hy", "cy", "returnedAlgoCount", "perfResults"},
	"cudnnGetCTCLossDescriptor":                                {"compType"},
	"cudnnGetCTCLossDescriptorEx":                              {"compType", "normMode", "gradMode"},
	"cudnnGetCTCLossDescriptor_v8":                             {"compType", "normMode", "gradMode", "maxLabelLength"},
	"cudnnGetCTCLossWorkspaceSize":                             {"sizeInBytes"},
	"cudnnGetCTCLossWorkspaceSize_v8":                          {"sizeInBytes"},
	"cudnnGetRNNTrainingReserveSize":                           {"sizeInBytes"},
	"cudnnMultiHeadAttnBackwardData":                           {"dqueries", "dkeys", "dvalues"},
	"cudnnMultiHeadAttnBackwardWeights":                        {"dweights"},
	"cudnnRNNBackwardData":                                     {"dx", "dhx", "dcx"},
	"cudnnRNNBackwardData_v8":                                  {"dx", "dhx", "dcx"},
	"cudnnRNNBackwardDataEx":                                   {"dx", "dhx", "dcx"},
	"cudnnRNNBackwardWeights_v8":                               {"y", "dweightSpace"},
	"cudnnRNNForwardTraining":                                  {"y", "hy", "cy"},
	"cudnnRNNForwardTrainingEx":                                {"y", "hy", "cy"},
	"cudnnSetCTCLossDescriptor":                                {"ctcLossDesc"},
	"cudnnSetCTCLossDescriptorEx":                              {"ctcLossDesc"},
	"cudnnSetCTCLossDescriptor_v8":                             {"ctcLossDesc"},
}
var ioParams = map[string][]string{
	"cudnnAddTensor":                                {"C"},
	"cudnnGetAlgorithmPerformance":                  {"algoPerf"},
	"cudnnOpTensor":                                 {"C"},
	"cudnnQueryRuntimeError":                        {"tag"},
	"cudnnReduceTensor":                             {"C"},
	"cudnnRestoreDropoutDescriptor":                 {"dropoutDesc"},
	"cudnnScaleTensor":                              {"y"},
	"cudnnSetActivationDescriptor":                  {"activationDesc"},
	"cudnnSetAlgorithmDescriptor":                   {"algorithmDesc"},
	"cudnnSetAlgorithmPerformance":                  {"algoPerf"},
	"cudnnSetDropoutDescriptor":                     {"dropoutDesc"},
	"cudnnSetFilter4dDescriptor":                    {"filterDesc"},
	"cudnnSetFilterNdDescriptor":                    {"filterDesc"},
	"cudnnSetPooling2dDescriptor":                   {"poolingDesc"},
	"cudnnSetPoolingNdDescriptor":                   {"poolingDesc"},
	"cudnnSetReduceTensorDescriptor":                {"reduceTensorDesc"},
	"cudnnSetSpatialTransformerNdDescriptor":        {"stDesc"},
	"cudnnSetTensor":                                {"y"},
	"cudnnSetTensor4dDescriptor":                    {"tensorDesc"},
	"cudnnSetTensor4dDescriptorEx":                  {"tensorDesc"},
	"cudnnSetTensorNdDescriptor":                    {"tensorDesc"},
	"cudnnConvolutionBackwardData":                  {"dx"},
	"cudnnConvolutionBiasActivationForward":         {"y"},
	"cudnnConvolutionForward":                       {"y"},
	"cudnnFindConvolutionBackwardDataAlgorithmEx":   {"dxDesc"},
	"cudnnFindConvolutionForwardAlgorithmEx":        {"y"},
	"cudnnGetConvolution2dDescriptor":               {"convDesc"},
	"cudnnGetConvolutionNdDescriptor":               {"convDesc"},
	"cudnnSetConvolution2dDescriptor":               {"convDesc"},
	"cudnnSetConvolutionNdDescriptor":               {"convDesc"},
	"cudnnConvolutionBackwardFilter":                {"dw"},
	"cudnnFindConvolutionBackwardFilterAlgorithmEx": {"dw"},
	"cudnnGetFusedOpsConstParamPackAttribute":       {"isNULL"},
	"cudnnGetRNNPaddingMode":                        {"rnnDesc"},
	"cudnnMultiHeadAttnForward":                     {"workSpace", "reserveSpace"},
	"cudnnRNNForward":                               {"workSpace", "reserveSpace"},
	"cudnnSetRNNDataDescriptor":                     {"RNNDataDesc"},
	"cudnnSetRNNDescriptor_v6":                      {"rnnDesc"},
	"cudnnSetRNNPaddingMode":                        {"rnnDesc"},
	"cudnnFindRNNBackwardDataAlgorithmEx":           {"reserveSpace"},
	"cudnnFindRNNBackwardWeightsAlgorithmEx":        {"dw"},
	"cudnnFindRNNForwardTrainingAlgorithmEx":        {"reserveSpace"},
	"cudnnMultiHeadAttnBackwardData":                {"workSpace", "reserveSpace"},
	"cudnnMultiHeadAttnBackwardWeights":             {"workSpace", "reserveSpace"},
	"cudnnRNNBackwardData":                          {"reserveSpace"},
	"cudnnRNNBackwardData_v8":                       {"workSpace", "reserveSpace"},
	"cudnnRNNBackwardDataEx":                        {"reserveSpace"},
	"cudnnRNNBackwardWeights":                       {"dw"},
	"cudnnRNNBackwardWeights_v8":                    {"workSpace", "reserveSpace"},
	"cudnnRNNBackwardWeightsEx":                     {"dw"},
	"cudnnRNNForwardTraining":                       {"reserveSpace"},
	"cudnnRNNForwardTrainingEx":                     {"reserveSpace"},
}
var docs = map[string]string{
	"cudnnActivationForward":                                   "Input. Handle to a previously created cuDNN context. For more information, see cudnnHandle_t.",
	"cudnnAddTensor":                                           "cudnnAddTensor adds the scaled values of a bias tensor to another tensor. Each dimension of the bias tensor A must match the corresponding dimension of the destination tensor C or must be equal to 1. In the latter case, the same value from the bias tensor for those dimensions will be used to blend into the C tensor.",
	"cudnnBatchNormalizationForwardInference":                  "Input. Handle to a previously created cuDNN library descriptor. For more information, see cudnnHandle_t.",
	"cudnnCreate":                                              "cudnnCreate initializes the cuDNN library and creates a handle to an opaque structure holding the cuDNN library context. It allocates hardware resources on the host and device and must be called prior to making any other cuDNN library calls.",
	"cudnnCreateActivationDescriptor":                          "cudnnCreateActivationDescriptor creates an activation descriptor object by allocating the memory needed to hold its opaque structure. For more information, see cudnnActivationDescriptor_t.",
	"cudnnCreateAlgorithmDescriptor":                           "cudnnCreateAlgorithmDescriptor has been deprecated in cuDNN 8.0.",
	"cudnnCreateAlgorithmPerformance":                          "cudnnCreateAlgorithmPerformance creates multiple algorithm performance objects by allocating the memory needed to hold their opaque structures.",
	"cudnnCreateDropoutDescriptor":                             "cudnnCreateDropoutDescriptor creates a generic dropout descriptor object by allocating the memory needed to hold its opaque structure. For more information, see cudnnDropoutDescriptor_t.",
	"cudnnCreateFilterDescriptor":                              "cudnnCreateFilterDescriptor creates a filter descriptor object by allocating the memory needed to hold its opaque structure. For more information, see cudnnFilterDescriptor_t.",
	"cudnnCreateLRNDescriptor":                                 "cudnnCreateLRNDescriptor allocates the memory needed to hold the data needed for LRN and DivisiveNormalization layers operation and returns a descriptor used with subsequent layer forward and backward calls.",
	"cudnnCreateOpTensorDescriptor":                            "cudnnCreateOpTensorDescriptor creates a tensor pointwise math descriptor. For more information, see cudnnOpTensorDescriptor_t.",
	"cudnnCreatePoolingDescriptor":                             "cudnnCreatePoolingDescriptor creates a pooling descriptor object by allocating the memory needed to hold its opaque structure.",
	"cudnnCreateReduceTensorDescriptor":                        "cudnnCreateReduceTensorDescriptor creates a reduced tensor descriptor object by allocating the memory needed to hold its opaque structure.",
	"cudnnCreateSpatialTransformerDescriptor":                  "cudnnCreateSpatialTransformerDescriptor creates a generic spatial transformer descriptor object by allocating the memory needed to hold its opaque structure.",
	"cudnnCreateTensorDescriptor":                              "cudnnCreateTensorDescriptor creates a generic tensor descriptor object by allocating the memory needed to hold its opaque structure. The data is initialized to all zeros.",
	"cudnnCreateTensorTransformDescriptor":                     "cudnnCreateTensorTransformDescriptor creates a tensor transform descriptor object by allocating the memory needed to hold its opaque structure. The tensor data is initialized to be all zero. Use the cudnnSetTensorTransformDescriptor() function to initialize the descriptor created by this function.",
	"cudnnDeriveBNTensorDescriptor":                            "cudnnDeriveBNTensorDescriptor derives a secondary tensor descriptor for the batch normalization scale, invVariance, bnBias, and bnScale subtensors from the layer's x data descriptor.",
	"cudnnDeriveNormTensorDescriptor":                          "cudnnDeriveNormTensorDescriptor derives tensor descriptors for the normalization mean, invariance, normBias, and normScale subtensors from the layer's x data descriptor and norm mode. normalization, mean, and invariance share the same descriptor while bias and scale share the same descriptor.",
	"cudnnDestroy":                                             "cudnnDestroy releases the resources used by the cuDNN handle. cudnnDestroy is usually the last call with a particular handle to the cuDNN handle. Because cudnnCreate() allocates some internal resources, the release of those resources by calling cudnnDestroy() will implicitly call cudaDeviceSynchronize; therefore, the recommended best practice is to call cudnnCreate/cudnnDestroy outside of performance-critical code paths.",
	"cudnnDestroyActivationDescriptor":                         "cudnnDestroyActivationDescriptor destroys a previously created activation descriptor object.",
	"cudnnDestroyAlgorithmDescriptor":                          "cudnnDestroyAlgorithmDescriptor has been deprecated in cuDNN 8.0.",
	"cudnnDestroyAlgorithmPerformance":                         "cudnnDestroyAlgorithmPerformance destroys a previously created algorithm descriptor object.",
	"cudnnDestroyDropoutDescriptor":                            "cudnnDestroyDropoutDescriptor destroys a previously created dropout descriptor object.",
	"cudnnDestroyFilterDescriptor":                             "cudnnDestroyFilterDescriptor destroys a previously created tensor 4D descriptor object.",
	"cudnnDestroyLRNDescriptor":                                "cudnnDestroyLRNDescriptor destroys a previously created LRN descriptor object.",
	"cudnnDestroyOpTensorDescriptor":                           "cudnnDestroyOpTensorDescriptor deletes a tensor pointwise math descriptor object.",
	"cudnnDestroyPoolingDescriptor":                            "cudnnDestroyPoolingDescriptor destroys a previously created pooling descriptor object.",
	"cudnnDestroyReduceTensorDescriptor":                       "cudnnDestroyReduceTensorDescriptor destroys a previously created reduce tensor descriptor object. When the input pointer is NULL, this function performs no destroy operation.",
	"cudnnDestroySpatialTransformerDescriptor":                 "cudnnDestroySpatialTransformerDescriptor destroys a previously created spatial transformer descriptor object.",
	"cudnnDestroyTensorDescriptor":                             "cudnnDestroyTensorDescriptor destroys a previously created tensor descriptor object. When the input pointer is NULL, this function performs no destroy operation.",
	"cudnnDestroyTensorTransformDescriptor":                    "Destroys a previously created tensor transform descriptor.",
	"cudnnDivisiveNormalizationForward":                        "The x-mean(x) which is often referred to as `subtractive normalization` portion of the computation can be implemented using cuDNN average pooling layer followed by a call to addTensor.",
	"cudnnDropoutForward":                                      "cudnnDropoutForward performs forward dropout operation over x returning results in y. If dropout was used as a parameter to cudnnSetDropoutDescriptor(), the approximately dropout fraction of x values will be replaced by a 0, and the rest will be scaled by 1/(1-dropout). cudnnDropoutForward should not be running concurrently with another cudnnDropoutForward() function using the same states.",
	"cudnnDropoutGetReserveSpaceSize":                          "cudnnDropoutGetReserveSpaceSize is used to query the amount of reserve needed to run dropout with the input dimensions given by xDesc. The same reserve space is expected to be passed to cudnnDropoutForward() and cudnnDropoutBackward(), and its contents is expected to remain unchanged between cudnnDropoutForward() and cudnnDropoutBackward() calls.",
	"cudnnDropoutGetStatesSize":                                "cudnnDropoutGetStatesSize is used to query the amount of space required to store the states of the random number generators used by cudnnDropoutForward() function.",
	"cudnnGetActivationDescriptor":                             "cudnnGetActivationDescriptor queries a previously initialized generic activation descriptor object.",
	"cudnnGetAlgorithmDescriptor":                              "cudnnGetAlgorithmDescriptor has been deprecated in cuDNN 8.0.",
	"cudnnGetAlgorithmPerformance":                             "cudnnGetAlgorithmPerformance has been deprecated in cuDNN 8.0.",
	"cudnnGetAlgorithmSpaceSize":                               "cudnnGetAlgorithmSpaceSize has been deprecated in cuDNN 8.0.",
	"cudnnGetCallback":                                         "cudnnGetCallback queries the internal states of cuDNN error reporting functionality.",
	"cudnnGetDropoutDescriptor":                                "cudnnGetDropoutDescriptor queries the fields of a previously initialized dropout descriptor.",
	"cudnnGetErrorString":                                      "cudnnGetErrorString converts the cuDNN status code to a NULL terminated (ASCIIZ) static string. For example, when the input argument is CUDNN_STATUS_SUCCESS, the returned string is CUDNN_STATUS_SUCCESS. When an invalid status value is passed to the function, the returned string is CUDNN_UNKNOWN_STATUS.",
	"cudnnGetFilter4dDescriptor":                               "cudnnGetFilter4dDescriptor queries the parameters of the previously initialized filter descriptor object.",
	"cudnnGetFilterNdDescriptor":                               "cudnnGetFilterNdDescriptor queries a previously initialized filter descriptor object.",
	"cudnnGetFilterSizeInBytes":                                "cudnnGetFilterSizeInBytes returns the size of the filter tensor in memory with respect to the given descriptor. It can be used to know the amount of GPU memory to be allocated to hold that filter tensor.",
	"cudnnGetLRNDescriptor":                                    "cudnnGetLRNDescriptor retrieves values stored in the previously initialized LRN descriptor object.",
	"cudnnGetOpTensorDescriptor":                               "cudnnGetOpTensorDescriptor returns the configuration of the passed tensor pointwise math descriptor.",
	"cudnnGetPooling2dDescriptor":                              "cudnnGetPooling2dDescriptor queries a previously created 2D pooling descriptor object.",
	"cudnnGetPooling2dForwardOutputDim":                        "cudnnGetPooling2dForwardOutputDim provides the output dimensions of a tensor after 2d pooling has been applied.",
	"cudnnGetPoolingNdDescriptor":                              "cudnnGetPoolingNdDescriptor queries a previously initialized generic pooling descriptor object.",
	"cudnnGetPoolingNdForwardOutputDim":                        "cudnnGetPoolingNdForwardOutputDim provides the output dimensions of a tensor after Nd pooling has been applied.",
	"cudnnGetProperty":                                         "cudnnGetProperty writes a specific part of the cuDNN library version number into the provided host storage.",
	"cudnnGetReduceTensorDescriptor":                           "cudnnGetReduceTensorDescriptor queries a previously initialized reduce tensor descriptor object.",
	"cudnnGetReductionIndicesSize":                             "cudnnGetReductionIndicesSize is a helper function to return the minimum size of the index space to be passed to the reduction given the input and output tensors.",
	"cudnnGetReductionWorkspaceSize":                           "cudnnGetReductionWorkspaceSize is a helper function to return the minimum size of the workspace to be passed to the reduction given the input and output tensors.",
	"cudnnGetStream":                                           "cudnnGetStream retrieves the user CUDA stream programmed in the cuDNN handle. When the user's CUDA stream is not set in the cuDNN handle, this function reports the null-stream.",
	"cudnnGetTensor4dDescriptor":                               "cudnnGetTensor4dDescriptor queries the parameters of the previously initialized tensor4D descriptor object.",
	"cudnnGetTensorNdDescriptor":                               "cudnnGetTensorNdDescriptor retrieves values stored in a previously initialized tensor descriptor object.",
	"cudnnGetTensorSizeInBytes":                                "cudnnGetTensorSizeInBytes returns the size of the tensor in memory in respect to the given descriptor. cudnnGetTensorSizeInBytes can be used to know the amount of GPU memory to be allocated to hold that tensor.",
	"cudnnGetTensorTransformDescriptor":                        "cudnnGetTensorTransformDescriptor returns the values stored in a previously initialized tensor transform descriptor.",
	"cudnnLRNCrossChannelForward":                              "cudnnLRNCrossChannelForward performs the forward LRN layer computation.",
	"cudnnNormalizationForwardInference":                       "Input. Handle to a previously created cuDNN library descriptor. For more information, see cudnnHandle_t.",
	"cudnnOpsInferVersionCheck":                                "cudnnOpsInferVersionCheck is the first of a series of corresponding functions that check for consistent library versions among DLL files for different modules.",
	"cudnnOpTensor":                                            "cudnnOpTensor implements the equation C = op(alpha1[0] * A, alpha2[0] * B) + beta[0] * C, given the tensors A, B, and C and the scaling factors alpha1, alpha2, and beta. The op to use is indicated by the descriptor cudnnOpTensorDescriptor_t, meaning, the type of opTensorDesc. Currently-supported ops are listed by the cudnnOpTensorOp_t enum.",
	"cudnnPoolingForward":                                      "cudnnPoolingForward computes pooling of input values (meaning, the maximum or average of several adjacent values) to produce an output with smaller height and/or width.",
	"cudnnQueryRuntimeError":                                   "cuDNN library functions perform extensive input argument checking before launching GPU kernels. The last step is to verify that the GPU kernel actually started. When a kernel fails to start, CUDNN_STATUS_EXECUTION_FAILED is returned by the corresponding API call. Typically, after a GPU kernel starts, no runtime checks are performed by the kernel itself - numerical results are simply written to output buffers.",
	"cudnnReduceTensor":                                        "cudnnReduceTensor reduces tensor A by implementing the equation C = alpha * reduce op ( A ) + beta * C, given tensors A and C and scaling factors alpha and beta. The reduction op to use is indicated by the descriptor reduceTensorDesc. Currently-supported ops are listed by the cudnnReduceTensorOp_t enum.",
	"cudnnRestoreAlgorithm":                                    "cudnnRestoreAlgorithm has been deprecated in cuDNN 8.0.",
	"cudnnRestoreDropoutDescriptor":                            "cudnnRestoreDropoutDescriptor restores a dropout descriptor to a previously saved-off state.",
	"cudnnSaveAlgorithm":                                       "cudnnSaveAlgorithm has been deprecated in cuDNN 8.0.",
	"cudnnScaleTensor":                                         "cudnnScaleTensor scales all the elements of a tensor by a given factor.",
	"cudnnSetActivationDescriptor":                             "cudnnSetActivationDescriptor initializes a previously created generic activation descriptor object.",
	"cudnnSetAlgorithmDescriptor":                              "cudnnSetAlgorithmDescriptor has been deprecated in cuDNN 8.0.",
	"cudnnSetAlgorithmPerformance":                             "cudnnSetAlgorithmPerformance has been deprecated in cuDNN 8.0.",
	"cudnnSetCallback":                                         "cudnnSetCallback sets the internal states of cuDNN error reporting functionality.",
	"cudnnSetDropoutDescriptor":                                "cudnnSetDropoutDescriptor initializes a previously created dropout descriptor object. If the states argument is equal to NULL, then the random number generator states won't be initialized, and only the dropout value will be set. The user is expected not to change the memory pointed at by states for the duration of the computation.",
	"cudnnSetFilter4dDescriptor":                               "cudnnSetFilter4dDescriptor initializes a previously created filter descriptor object into a 4D filter. The layout of the filters must be contiguous in memory.",
	"cudnnSetFilterNdDescriptor":                               "cudnnSetFilterNdDescriptor initializes a previously created filter descriptor object. The layout of the filters must be contiguous in memory.",
	"cudnnSetLRNDescriptor":                                    "cudnnSetLRNDescriptor initializes a previously created LRN descriptor object.",
	"cudnnSetOpTensorDescriptor":                               "cudnnSetOpTensorDescriptor initializes a tensor pointwise math descriptor.",
	"cudnnSetPooling2dDescriptor":                              "cudnnSetPooling2dDescriptor initializes a previously created generic pooling descriptor object into a 2D description.",
	"cudnnSetPoolingNdDescriptor":                              "cudnnSetPoolingNdDescriptor initializes a previously created generic pooling descriptor object.",
	"cudnnSetReduceTensorDescriptor":                           "cudnnSetReduceTensorDescriptor initializes a previously created reduce tensor descriptor object.",
	"cudnnSetSpatialTransformerNdDescriptor":                   "cudnnSetSpatialTransformerNdDescriptor initializes a previously created generic spatial transformer descriptor object.",
	"cudnnSetStream":                                           "cudnnSetStream sets the user's CUDA stream in the cuDNN handle. The new stream will be used to launch cuDNN GPU kernels or to synchronize to this stream when cuDNN kernels are launched in the internal streams. If the cuDNN library stream is not set, all kernels use the default (NULL) stream. Setting the user stream in the cuDNN handle guarantees the issue-order execution of cuDNN calls and other GPU kernels launched in the same stream.",
	"cudnnSetTensor":                                           "cudnnSetTensor sets all the elements of a tensor to a given value.",
	"cudnnSetTensor4dDescriptor":                               "cudnnSetTensor4dDescriptor initializes a previously created generic tensor descriptor object into a 4D tensor. The strides of the four dimensions are inferred from the format parameter and set in such a way that the data is contiguous in memory with no padding between dimensions.",
	"cudnnSetTensor4dDescriptorEx":                             "cudnnSetTensor4dDescriptorEx initializes a previously created generic tensor descriptor object into a 4D tensor, similarly to cudnnSetTensor4dDescriptor() but with the strides explicitly passed as parameters. cudnnSetTensor4dDescriptorEx can be used to lay out the 4D tensor in any order or simply to define gaps between dimensions.",
	"cudnnSetTensorNdDescriptor":                               "cudnnSetTensorNdDescriptor initializes a previously created generic tensor descriptor object.",
	"cudnnSetTensorNdDescriptorEx":                             "cudnnSetTensorNdDescriptorEx initializes an n-D tensor descriptor.",
	"cudnnSetTensorTransformDescriptor":                        "cudnnSetTensorTransformDescriptor initializes a tensor transform descriptor that was previously created using the cudnnCreateTensorTransformDescriptor() function.",
	"cudnnSoftmaxForward":                                      "cudnnSoftmaxForward computes the softmax function.",
	"cudnnSpatialTfGridGeneratorForward":                       "cudnnSpatialTfGridGeneratorForward generates a grid of coordinates in the input tensor corresponding to each pixel from the output tensor.",
	"cudnnSpatialTfSamplerForward":                             "cudnnSpatialTfSamplerForward performs a sampler operation and generates the output tensor using the grid given by the grid generator.",
	"cudnnTransformFilter":                                     "cudnnTransformFilter converts the filter between different formats, data types, or dimensions based on the described transformation. It can be used to convert a filter with an unsupported layout format to a filter with a supported layout format.",
	"cudnnTransformTensor":                                     "cudnnTransformTensor copies the scaled data from one tensor to another tensor with a different layout. Those descriptors need to have the same dimensions but not necessarily the same strides. The input and output tensors must not overlap in any way (meaning, tensors cannot be transformed in place). cudnnTransformTensor can be used to convert a tensor with an unsupported format to a supported one.",
	"cudnnTransformTensorEx":                                   "cudnnTransformTensorEx converts the tensor layouts between different formats. It can be used to convert a tensor with an unsupported layout format to a tensor with a supported layout format.",
	"cudnnActivationBackward":                                  "Input. Handle to a previously created cuDNN context. For more information, see cudnnHandle_t.",
	"cudnnBatchNormalizationBackward":                          "For more information, see cudnnDeriveBNTensorDescriptor() for the secondary tensor descriptor generation for the parameters used in this function.",
	"cudnnBatchNormalizationBackwardEx":                        "If workspace is NULL and workSpaceSizeInBytes of zero is passed in, this API will function exactly like the non-extended function cudnnBatchNormalizationBackward.",
	"cudnnBatchNormalizationForwardTraining":                   "Handle to a previously created cuDNN library descriptor. For more information, see cudnnHandle_t.",
	"cudnnBatchNormalizationForwardTrainingEx":                 "cudnnBatchNormalizationForwardTrainingEx is an extension of the cudnnBatchNormalizationForwardTraining() for performing the forward batch normalization layer computation.",
	"cudnnDivisiveNormalizationBackward":                       "cudnnDivisiveNormalizationBackward performs the backward DivisiveNormalization layer computation.",
	"cudnnDropoutBackward":                                     "cudnnDropoutBackward performs backward dropout operation over dy returning results in dx. If during forward dropout operation value from x was propagated to y then during backward operation value from dy will be propagated to dx, otherwise, dx value will be set to 0.",
	"cudnnGetBatchNormalizationBackwardExWorkspaceSize":        "cudnnGetBatchNormalizationBackwardExWorkspaceSize returns the amount of GPU memory workspace the user should allocate to be able to call cudnnGetBatchNormalizationBackwardExWorkspaceSize() function for the specified bnOps input setting. The workspace allocated will then be passed to the function cudnnGetBatchNormalizationBackwardExWorkspaceSize().",
	"cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize": "cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize returns the amount of GPU memory workspace the user should allocate to be able to call cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize() function for the specified bnOps input setting. The workspace allocated should then be passed by the user to the function cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize().",
	"cudnnGetBatchNormalizationTrainingExReserveSpaceSize":     "cudnnGetBatchNormalizationTrainingExReserveSpaceSize returns the amount of reserve GPU memory workspace the user should allocate for the batch normalization operation, for the specified bnOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered.",
	"cudnnGetNormalizationBackwardWorkspaceSize":               "cudnnGetNormalizationBackwardWorkspaceSize returns the amount of GPU memory workspace the user should allocate to be able to call cudnnNormalizationBackward() function for the specified normOps and algo input setting. The workspace allocated will then be passed to the function cudnnNormalizationBackward().",
	"cudnnGetNormalizationForwardTrainingWorkspaceSize":        "cudnnGetNormalizationForwardTrainingWorkspaceSize returns the amount of GPU memory workspace the user should allocate to be able to call cudnnNormalizationForwardTraining() function for the specified normOps and algo input setting. The workspace allocated should then be passed by the user to the function cudnnNormalizationForwardTraining().",
	"cudnnGetNormalizationTrainingReserveSpaceSize":            "cudnnGetNormalizationTrainingReserveSpaceSize returns the amount of reserve GPU memory workspace the user should allocate for the normalization operation, for the specified normOps input setting. In contrast to the workspace, the reserved space should be preserved between the forward and backward calls, and the data should not be altered.",
	"cudnnLRNCrossChannelBackward":                             "cudnnLRNCrossChannelBackward performs the backward LRN layer computation.",
	"cudnnNormalizationBackward":                               "The epsilon value has to be the same during training, backpropagation, and inference. cudnnNormalizationBackward workspace is not required to be clean. Moreover, the workspace does not have to remain unchanged between the forward and backward pass, as it is not used for passing any information.",
	"cudnnNormalizationForwardTraining":                        "cudnnNormalizationForwardTraining workspace is not required to be clean. Moreover, the workspace does not have to remain unchanged between the forward and backward pass, as it is not used for passing any information. cudnnNormalizationForwardTraining extended function can accept a *workspace pointer to the GPU workspace, and workSpaceSizeInBytes, the size of the workspace, from the user.",
	"cudnnOpsTrainVersionCheck":                                "cudnnOpsTrainVersionCheck checks whether the version of the OpsTrain subset of the library is consistent with the other sub-libraries.",
	"cudnnPoolingBackward":                                     "cudnnPoolingBackward computes the gradient of a pooling operation.",
	"cudnnSoftmaxBackward":                                     "cudnnSoftmaxBackward computes the gradient of the softmax function.",
	"cudnnSpatialTfGridGeneratorBackward":                      "cudnnSpatialTfGridGeneratorBackward computes the gradient of a grid generation operation.",
	"cudnnSpatialTfSamplerBackward":                            "cudnnSpatialTfSamplerBackward computes the gradient of a sampling operation.",
	"cudnnBackendCreateDescriptor":                             "Input. One among the enumerated cudnnBackendDescriptorType_t.",
	"cudnnBackendDestroyDescriptor":                            "cudnnBackendDestroyDescriptor destroys instances of cudnnBackendDescriptor_t that were previously created using cudnnBackendCreateDescriptor().",
	"cudnnBackendExecute":                                      "The data and the working space are encapsulated in the VariantPack.",
	"cudnnBackendFinalize":                                     "cudnnBackendFinalize finalizes the memory pointed to by the descriptor. The type of finalization is done depending on the descriptorType argument with which the descriptor was created using cudnnBackendCreate() or initialized using cudnnBackendInitialize().",
	"cudnnBackendGetAttribute":                                 "cudnnBackendGetAttribute retrieves the value(s) of an attribute of a descriptor. attributeName is the name of the attribute whose value is requested. The attributeType is the type of attribute. requestsedElementCount is the number of elements to be potentially retrieved. The number of elements for the requested attribute is stored in elementCount. The retrieved values are stored in arrayOfElements. When the attribute is expected to have a single value, arrayOfElements can be pointer to the output value. cudnnBackendGetAttribute will return CUDNN_STATUS_NOT_INTIALIZED if the descriptor was already successfully finalized.",
	"cudnnBackendInitialize":                                   "cudnnBackendInitialize repurposes a pre-allocated memory pointed to by a descriptor of size sizeInByte to a backend descriptor of type descriptorType. The necessary size for a descriptor type can be acquired by calling the function cudnnBackendGetSizeOf(). The finalized state of the descriptor is set to false.",
	"cudnnBackendSetAttribute":                                 "cudnnBackendSetAttribute sets an attribute of a descriptor to value(s) provided as a pointer. descriptor is the descriptor to be set. attributeName is the name of the attribute to be set. attributeType is the type of attribute. The value to which the attribute is set, is pointed by the arrayOfElements. The number of elements is given by elementCount. cudnnBackendSetAttribute will return CUDNN_STATUS_NOT_INTIALIZED if the descriptor is already successfully finalized using cudnnBackendFinalize().",
	"cudnnConvolutionBackwardData":                             "cudnnConvolutionBackwardData computes the convolution data gradient of the tensor dy, where y is the output of the forward convolution in cudnnConvolutionForward(). It uses the specified algo, and returns the results in the output tensor dx. Scaling factors alpha and beta can be used to scale the computed result or accumulate with the current dx.",
	"cudnnConvolutionBiasActivationForward":                    "Input. Handle to a previously created cuDNN context. For more information, see cudnnHandle_t.",
	"cudnnConvolutionForward":                                  "cudnnConvolutionForward executes convolutions or cross-correlations over x using filters specified with w, returning results in y. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively.",
	"cudnnCreateConvolutionDescriptor":                         "cudnnCreateConvolutionDescriptor creates a convolution descriptor object by allocating the memory needed to hold its opaque structure. For more information, see cudnnConvolutionDescriptor_t.",
	"cudnnDestroyConvolutionDescriptor":                        "cudnnDestroyConvolutionDescriptor destroys a previously created convolution descriptor object.",
	"cudnnFindConvolutionBackwardDataAlgorithm":                "cudnnFindConvolutionBackwardDataAlgorithm attempts all algorithms available for cudnnConvolutionBackwardData(). It will attempt both the provided convDescmathType and CUDNN_DEFAULT_MATH (assuming the two differ).",
	"cudnnFindConvolutionBackwardDataAlgorithmEx":              "cudnnFindConvolutionBackwardDataAlgorithmEx attempts all algorithms available for cudnnConvolutionBackwardData(). It will attempt both the provided convDescmathType and CUDNN_DEFAULT_MATH (assuming the two differ).",
	"cudnnFindConvolutionForwardAlgorithm":                     "cudnnFindConvolutionForwardAlgorithm attempts all algorithms available for cudnnConvolutionForward(). It will attempt both the provided convDescmathType and CUDNN_DEFAULT_MATH (assuming the two differ).",
	"cudnnFindConvolutionForwardAlgorithmEx":                   "cudnnFindConvolutionForwardAlgorithmEx attempts all algorithms available for cudnnConvolutionForward(). It will attempt both the provided convDescmathType and CUDNN_DEFAULT_MATH (assuming the two differ).",
	"cudnnGetConvolution2dDescriptor":                          "cudnnGetConvolution2dDescriptor queries a previously initialized 2D convolution descriptor object.",
	"cudnnGetConvolution2dForwardOutputDim":                    "cudnnGetConvolution2dForwardOutputDim returns the dimensions of the resulting 4D tensor of a 2D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor cudnnGetConvolution2dForwardOutputDim can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution.",
	"cudnnGetConvolutionBackwardDataAlgorithmMaxCount":         "cudnnGetConvolutionBackwardDataAlgorithmMaxCount returns the maximum number of algorithms which can be returned from cudnnFindConvolutionBackwardDataAlgorithm() and cudnnGetConvolutionForwardAlgorithm_v7(). cudnnGetConvolutionBackwardDataAlgorithmMaxCount is the sum of all algorithms plus the sum of all algorithms with Tensor Core operations supported for the current device.",
	"cudnnGetConvolutionBackwardDataAlgorithm_v7":              "cudnnGetConvolutionBackwardDataAlgorithm_v7 serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionBackwardData() for the given layer specifications. cudnnGetConvolutionBackwardDataAlgorithm_v7 will return all algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal heuristic) relative performance with the fastest being index 0 of perfResults. For an exhaustive search for the fastest algorithm, use cudnnFindConvolutionBackwardDataAlgorithm(). The total number of resulting algorithms can be queried through the returnedAlgoCount variable.",
	"cudnnGetConvolutionBackwardDataWorkspaceSize":             "cudnnGetConvolutionBackwardDataWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnConvolutionBackwardData() with the specified algorithm. The workspace allocated will then be passed to the routine cudnnConvolutionBackwardData(). The specified algorithm can be the result of the call to cudnnGetConvolutionBackwardDataAlgorithm_v7() or can be chosen arbitrarily by the user. Note that not every algorithm is available for every configuration of the input tensor and/or every configuration of the convolution descriptor.",
	"cudnnGetConvolutionForwardAlgorithmMaxCount":              "cudnnGetConvolutionForwardAlgorithmMaxCount returns the maximum number of algorithms which can be returned from cudnnFindConvolutionForwardAlgorithm() and cudnnGetConvolutionForwardAlgorithm_v7(). cudnnGetConvolutionForwardAlgorithmMaxCount is the sum of all algorithms plus the sum of all algorithms with Tensor Core operations supported for the current device.",
	"cudnnGetConvolutionForwardAlgorithm_v7":                   "cudnnGetConvolutionForwardAlgorithm_v7 serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionForward() for the given layer specifications. cudnnGetConvolutionForwardAlgorithm_v7 will return all algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal heuristic) relative performance with the fastest being index 0 of perfResults. For an exhaustive search for the fastest algorithm, use cudnnFindConvolutionForwardAlgorithm(). The total number of resulting algorithms can be queried through the returnedAlgoCount variable.",
	"cudnnGetConvolutionForwardWorkspaceSize":                  "cudnnGetConvolutionForwardWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnConvolutionForward() with the specified algorithm. The workspace allocated will then be passed to the routine cudnnConvolutionForward(). The specified algorithm can be the result of the call to cudnnGetConvolutionForwardAlgorithm_v7() or can be chosen arbitrarily by the user. Note that not every algorithm is available for every configuration of the input tensor and/or every configuration of the convolution descriptor.",
	"cudnnGetConvolutionGroupCount":                            "cudnnGetConvolutionGroupCount returns the group count specified in the given convolution descriptor.",
	"cudnnGetConvolutionMathType":                              "cudnnGetConvolutionMathType returns the math type specified in a given convolution descriptor.",
	"cudnnGetConvolutionNdDescriptor":                          "cudnnGetConvolutionNdDescriptor queries a previously initialized convolution descriptor object.",
	"cudnnGetConvolutionNdForwardOutputDim":                    "cudnnGetConvolutionNdForwardOutputDim returns the dimensions of the resulting n-D tensor of a nbDims-2-D convolution, given the convolution descriptor, the input tensor descriptor and the filter descriptor cudnnGetConvolutionNdForwardOutputDim can help to setup the output tensor and allocate the proper amount of memory prior to launch the actual convolution.",
	"cudnnGetConvolutionReorderType":                           "cudnnGetConvolutionReorderType retrieves the convolution reorder type from the given convolution descriptor.",
	"cudnnGetFoldedConvBackwardDataDescriptors":                "cudnnGetFoldedConvBackwardDataDescriptors calculates folding descriptors for backward data gradient. It takes as input the data descriptors along with convolution descriptor and computes the folded data descriptors and the folding transform descriptors. These can then be used to do the actual folding transform.",
	"cudnnIm2Col":                                              "Input. Handle to a previously created cuDNN context.",
	"cudnnReorderFilterAndBias":                                "cudnnReorderFilterAndBias cudnnReorderFilterAndBias() reorders the filter and bias values. It can be used to enhance the inference time by separating the reordering operation from convolution.",
	"cudnnSetConvolution2dDescriptor":                          "cudnnSetConvolution2dDescriptor initializes a previously created convolution descriptor object into a 2D correlation. cudnnSetConvolution2dDescriptor assumes that the tensor and filter descriptors correspond to the forward convolution path and checks if their settings are valid. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer.",
	"cudnnSetConvolutionGroupCount":                            "cudnnSetConvolutionGroupCount allows the user to specify the number of groups to be used in the associated convolution.",
	"cudnnSetConvolutionMathType":                              "cudnnSetConvolutionMathType allows the user to specify whether or not the use of tensor op is permitted in the library routines associated with a given convolution descriptor.",
	"cudnnSetConvolutionNdDescriptor":                          "cudnnSetConvolutionNdDescriptor initializes a previously created generic convolution descriptor object into a n-D correlation. That same convolution descriptor can be reused in the backward path provided it corresponds to the same layer. The convolution computation will be done in the specified dataType, which can be potentially different from the input/output tensors.",
	"cudnnSetConvolutionReorderType":                           "cudnnSetConvolutionReorderType sets the convolution reorder type for the given convolution descriptor.",
	"cudnnConvolutionBackwardBias":                             "cudnnConvolutionBackwardBias computes the convolution function gradient with respect to the bias, which is the sum of every element belonging to the same feature map across all of the images of the input tensor. Therefore, the number of elements produced is equal to the number of features maps of the input tensor.",
	"cudnnConvolutionBackwardFilter":                           "cudnnConvolutionBackwardFilter computes the convolution weight (filter) gradient of the tensor dy, where y is the output of the forward convolution in cudnnConvolutionForward(). It uses the specified algo, and returns the results in the output tensor dw. Scaling factors alpha and beta can be used to scale the computed result or accumulate with the current dw.",
	"cudnnCreateFusedOpsConstParamPack":                        "cudnnCreateFusedOpsConstParamPack creates an opaque structure to store the various problem size information, such as the shape, layout and the type of tensors, and the descriptors for convolution and activation, for the selected sequence of cudnnFusedOps computations.",
	"cudnnCreateFusedOpsPlan":                                  "cudnnCreateFusedOpsPlan creates the plan descriptor for the cudnnFusedOps computation. cudnnCreateFusedOpsPlan descriptor contains the plan information, including the problem type and size, which kernels should be run, and the internal workspace partition.",
	"cudnnCreateFusedOpsVariantParamPack":                      "cudnnCreateFusedOpsVariantParamPack creates a descriptor for cudnnFusedOps constant parameters.",
	"cudnnDestroyFusedOpsConstParamPack":                       "cudnnDestroyFusedOpsConstParamPack destroys a previously-created cudnnFusedOpsConstParamPack_t structure.",
	"cudnnDestroyFusedOpsPlan":                                 "cudnnDestroyFusedOpsPlan destroys the plan descriptor provided.",
	"cudnnDestroyFusedOpsVariantParamPack":                     "cudnnDestroyFusedOpsVariantParamPack destroys a previously-created descriptor for cudnnFusedOps constant parameters.",
	"cudnnFindConvolutionBackwardFilterAlgorithm":              "cudnnFindConvolutionBackwardFilterAlgorithm attempts all algorithms available for cudnnConvolutionBackwardFilter(). It will attempt both the provided convDescmathType and CUDNN_DEFAULT_MATH (assuming the two differ).",
	"cudnnFindConvolutionBackwardFilterAlgorithmEx":            "cudnnFindConvolutionBackwardFilterAlgorithmEx attempts all algorithms available for cudnnConvolutionBackwardFilter(). It will attempt both the provided convDescmathType and CUDNN_DEFAULT_MATH (assuming the two differ).",
	"cudnnFusedOpsExecute":                                     "cudnnFusedOpsExecute executes the sequence of cudnnFusedOps operations.",
	"cudnnGetConvolutionBackwardFilterAlgorithmMaxCount":       "cudnnGetConvolutionBackwardFilterAlgorithmMaxCount returns the maximum number of algorithms which can be returned from cudnnFindConvolutionBackwardFilterAlgorithm() and cudnnGetConvolutionForwardAlgorithm_v7(). cudnnGetConvolutionBackwardFilterAlgorithmMaxCount is the sum of all algorithms plus the sum of all algorithms with Tensor Core operations supported for the current device.",
	"cudnnGetConvolutionBackwardFilterAlgorithm_v7":            "cudnnGetConvolutionBackwardFilterAlgorithm_v7 serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionBackwardFilter() for the given layer specifications. cudnnGetConvolutionBackwardFilterAlgorithm_v7 will return all algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) sorted by expected (based on internal heuristic) relative performance with fastest being index 0 of perfResults. For an exhaustive search for the fastest algorithm, use cudnnFindConvolutionBackwardFilterAlgorithm(). The total number of resulting algorithms can be queried through the returnedAlgoCount variable.",
	"cudnnGetConvolutionBackwardFilterWorkspaceSize":           "cudnnGetConvolutionBackwardFilterWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnConvolutionBackwardFilter() with the specified algorithm. The workspace allocated will then be passed to the routine cudnnConvolutionBackwardFilter(). The specified algorithm can be the result of the call to cudnnGetConvolutionBackwardFilterAlgorithm_v7() or can be chosen arbitrarily by the user. Note that not every algorithm is available for every configuration of the input tensor and/or every configuration of the convolution descriptor.",
	"cudnnGetFusedOpsConstParamPackAttribute":                  "cudnnGetFusedOpsConstParamPackAttribute retrieves the values of the descriptor pointed to by the param pointer input. The type of the descriptor is indicated by the enum value of paramLabel input.",
	"cudnnGetFusedOpsVariantParamPackAttribute":                "cudnnGetFusedOpsVariantParamPackAttribute retrieves the settings of the variable parameter pack descriptor.",
	"cudnnMakeFusedOpsPlan":                                    "cudnnMakeFusedOpsPlan determines the optimum kernel to execute, and the workspace size the user should allocate, prior to the actual execution of the fused operations by cudnnFusedOpsExecute().",
	"cudnnSetFusedOpsConstParamPackAttribute":                  "cudnnSetFusedOpsConstParamPackAttribute sets the descriptor pointed to by the param pointer input. The type of the descriptor to be set is indicated by the enum value of the paramLabel input.",
	"cudnnSetFusedOpsVariantParamPackAttribute":                "cudnnSetFusedOpsVariantParamPackAttribute sets the variable parameter pack descriptor.",
	"cudnnAdvInferVersionCheck":                                "cudnnAdvInferVersionCheck checks to see whether the version of the AdvInfer subset of the library is consistent with the other sub-libraries.",
	"cudnnBuildRNNDynamic":                                     "cudnnBuildRNNDynamic compiles the RNN persistent code using CUDA runtime compilation library (NVRTC) when the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo is selected. The code is tailored to the current GPU and specific hyperparameters (miniBatch). cudnnBuildRNNDynamic call is expected to be expensive in terms of runtime and should be invoked infrequently. Note that the CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo does not support variable length sequences within the batch.",
	"cudnnCreateAttnDescriptor":                                "cudnnCreateAttnDescriptor creates one instance of an opaque attention descriptor object by allocating the host memory for it and initializing all descriptor fields. The function writes NULL to attnDesc when the attention descriptor object cannot be allocated.",
	"cudnnCreatePersistentRNNPlan":                             "cudnnCreatePersistentRNNPlan has been deprecated in cuDNN 8.0. Use cudnnBuildRNNDynamic() instead of cudnnCreatePersistentRNNPlan().",
	"cudnnCreateRNNDataDescriptor":                             "cudnnCreateRNNDataDescriptor creates a RNN data descriptor object by allocating the memory needed to hold its opaque structure.",
	"cudnnCreateRNNDescriptor":                                 "cudnnCreateRNNDescriptor creates a generic RNN descriptor object by allocating the memory needed to hold its opaque structure.",
	"cudnnCreateSeqDataDescriptor":                             "cudnnCreateSeqDataDescriptor creates one instance of an opaque sequence data descriptor object by allocating the host memory for it and initializing all descriptor fields. The function writes NULL to seqDataDesc when the sequence data descriptor object cannot be allocated.",
	"cudnnDestroyAttnDescriptor":                               "cudnnDestroyAttnDescriptor destroys the attention descriptor object and releases its memory. The attnDesc argument can be NULL. Invoking cudnnDestroyAttnDescriptor() with a NULL argument is a no operation (NOP).",
	"cudnnDestroyPersistentRNNPlan":                            "cudnnDestroyPersistentRNNPlan destroys a previously created persistent RNN plan object.",
	"cudnnDestroyRNNDataDescriptor":                            "cudnnDestroyRNNDataDescriptor destroys a previously created RNN data descriptor object.",
	"cudnnDestroyRNNDescriptor":                                "cudnnDestroyRNNDescriptor destroys a previously created RNN descriptor object.",
	"cudnnDestroySeqDataDescriptor":                            "cudnnDestroySeqDataDescriptor destroys the sequence data descriptor object and releases its memory. The seqDataDesc argument can be NULL. Invoking cudnnDestroySeqDataDescriptor() with a NULL argument is a no operation (NOP).",
	"cudnnFindRNNForwardInferenceAlgorithmEx":                  "cudnnFindRNNForwardInferenceAlgorithmEx attempts all available cuDNN algorithms for cudnnRNNForwardInference(), using user-allocated GPU memory. It outputs the parameters that influence the performance of the algorithm to a user-allocated array of cudnnAlgorithmPerformance_t. These parameter metrics are written in sorted fashion where the first element has the lowest compute time.",
	"cudnnGetAttnDescriptor":                                   "cudnnGetAttnDescriptor retrieves settings from the previously created attention descriptor. The user can assign NULL to any pointer except attnDesc when the retrieved value is not needed.",
	"cudnnGetMultiHeadAttnBuffers":                             "The user must allocate weight, work, and reserve space buffer sizes in the GPU memory using cudaMalloc() with the reported buffer sizes. The buffers can be also carved out from a larger chunk of allocated memory but the buffer addresses must be at least 16B aligned.",
	"cudnnGetMultiHeadAttnWeights":                             "cudnnGetMultiHeadAttnWeights obtains the shape of the weight or bias tensor. It also retrieves the start address of tensor data located in the weight buffer. Use the wKind argument to select a particular tensor. For more information, see cudnnMultiHeadAttnWeightKind_t for the description of the enumerant type.",
	"cudnnGetRNNBiasMode":                                      "cudnnGetRNNBiasMode has been deprecated in cuDNN 8.0. Use cudnnGetRNNDescriptor_v8() instead of cudnnGetRNNBiasMode()",
	"cudnnGetRNNDataDescriptor":                                "cudnnGetRNNDataDescriptor retrieves a previously created RNN data descriptor object.",
	"cudnnGetRNNDescriptor_v6":                                 "cudnnGetRNNDescriptor_v6 has been deprecated in cuDNN 8.0. Use cudnnGetRNNDescriptor_v8() instead of cudnnGetRNNDescriptor_v6().",
	"cudnnGetRNNDescriptor_v8":                                 "cudnnGetRNNDescriptor_v8 retrieves RNN network parameters that were configured by cudnnSetRNNDescriptor_v8(). The user can assign NULL to any pointer except rnnDesc when the retrieved value is not needed. The function does not check the validity of retrieved parameters.",
	"cudnnGetRNNLinLayerBiasParams":                            "cudnnGetRNNLinLayerBiasParams has been deprecated in cuDNN 8.0. Use cudnnGetRNNWeightParams() instead of cudnnGetRNNLinLayerBiasParams().",
	"cudnnGetRNNLinLayerMatrixParams":                          "cudnnGetRNNLinLayerMatrixParams has been deprecated in cuDNN 8.0 . Use cudnnGetRNNWeightParams() instead of cudnnGetRNNLinLayerMatrixParams().",
	"cudnnGetRNNMatrixMathType":                                "cudnnGetRNNMatrixMathType has been deprecated in cuDNN 8.0. Use cudnnGetRNNDescriptor_v8() instead of cudnnGetRNNMatrixMathType().",
	"cudnnGetRNNPaddingMode":                                   "cudnnGetRNNPaddingMode has been deprecated in cuDNN 8.0. Use cudnnGetRNNDescriptor_v8() instead of cudnnGetRNNPaddingMode().",
	"cudnnGetRNNParamsSize":                                    "cudnnGetRNNParamsSize has been deprecated in cuDNN 8.0. Use cudnnGetRNNWeightSpaceSize() instead of cudnnGetRNNParamsSize().",
	"cudnnGetRNNProjectionLayers":                              "cudnnGetRNNProjectionLayers has been deprecated in cuDNN 8.0. Use cudnnGetRNNDescriptor_v8() instead of cudnnGetRNNProjectionLayers().",
	"cudnnGetRNNTempSpaceSizes":                                "cudnnGetRNNTempSpaceSizes computes the work and reserve space buffer sizes based on the RNN network geometry stored in rnnDesc, designated usage (inference or training) defined by the fMode argument, and the current RNN data dimensions (maxSeqLength, batchSize) retrieved from xDesc. When RNN data dimensions change, the cudnnGetRNNTempSpaceSizes() must be called again because RNN temporary buffer sizes are not monotonic.",
	"cudnnGetRNNWeightParams":                                  "cudnnGetRNNWeightParams is used to obtain the start address and shape of every RNN weight matrix and bias vector in each pseudo-layer within the recurrent network.",
	"cudnnGetRNNWeightSpaceSize":                               "cudnnGetRNNWeightSpaceSize reports the required size of the weight space buffer in bytes. The weight space buffer holds all RNN weight matrices and bias vectors.",
	"cudnnGetRNNWorkspaceSize":                                 "cudnnGetRNNWorkspaceSize has been deprecated in cuDNN 8.0. Use cudnnGetRNNTempSpaceSizes() instead of cudnnGetRNNWorkspaceSize().",
	"cudnnGetSeqDataDescriptor":                                "cudnnGetSeqDataDescriptor retrieves settings from a previously created sequence data descriptor. The user can assign NULL to any pointer except seqDataDesc when the retrieved value is not needed. The nbDimsRequested argument applies to both dimA[] and axes[] arrays. A positive value of nbDimsRequested or seqLengthSizeRequested is ignored when the corresponding array, dimA[], axes[], or seqLengthArray[] is NULL.",
	"cudnnMultiHeadAttnForward":                                "The cudnnMultiHeadAttnForward() function computes the forward responses of the multi-head attention layer. When reserveSpaceSizeInBytes=0 and reserveSpace=NULL, the function operates in the inference mode in which backward (gradient) functions are not invoked, otherwise, the training mode is assumed. In the training mode, the reserve space is used to pass intermediate results from cudnnMultiHeadAttnForward() to cudnnMultiHeadAttnBackwardData() and from cudnnMultiHeadAttnBackwardData() to cudnnMultiHeadAttnBackwardWeights().",
	"cudnnRNNForward":                                          "cudnnRNNForward computes the forward response of the recurrent neural network described by rnnDesc with inputs in x, hx, cx, and weights/biases in the weightSpace buffer. RNN outputs are written to y, hy, and cy buffers. Locations of x, y, hx, cx, hy, and cy signals in the multi-layer RNN model are shown in the Figure below. Note that internal RNN signals between time-steps and between layers are not exposed to the user.",
	"cudnnRNNForwardInference":                                 "cudnnRNNForwardInference has been deprecated in cuDNN 8.0. Use cudnnRNNForward() instead of cudnnRNNForwardInference().",
	"cudnnRNNForwardInferenceEx":                               "cudnnRNNForwardInferenceEx has been deprecated in cuDNN 8.0. Use cudnnRNNForward() instead of cudnnRNNForwardInference().",
	"cudnnRNNGetClip":                                          "cudnnRNNGetClip has been deprecated in cuDNN 8.0. Use cudnnRNNGetClip_v8() instead of cudnnRNNGetClip().",
	"cudnnRNNGetClip_v8":                                       "Retrieves the current LSTM cell clipping parameters, and stores them in the arguments provided. The user can assign NULL to any pointer except rnnDesc when the retrieved value is not needed. The function does not check the validity of retrieved parameters.",
	"cudnnRNNSetClip":                                          "cudnnRNNSetClip has been deprecated in cuDNN 8.0. Use cudnnRNNSetClip_v8() instead of cudnnRNNSetClip().",
	"cudnnRNNSetClip_v8":                                       "Sets the LSTM cell clipping mode. The LSTM clipping is disabled by default. When enabled, clipping is applied to all layers. cudnnRNNSetClip_v8 cudnnRNNSetClip() function does not affect the work, reserve, and weight-space buffer sizes and may be called multiple times.",
	"cudnnSetAttnDescriptor":                                   "cudnnSetAttnDescriptor configures a multi-head attention descriptor that was previously created using the cudnnCreateAttnDescriptor() function. The function sets attention parameters that are necessary to compute internal buffer sizes, dimensions of weight and bias tensors, or to select optimized code paths.",
	"cudnnSetPersistentRNNPlan":                                "cudnnSetPersistentRNNPlan sets the persistent RNN plan to be executed when using rnnDesc and CUDNN_RNN_ALGO_PERSIST_DYNAMIC algo.",
	"cudnnSetRNNBiasMode":                                      "cudnnSetRNNBiasMode has been deprecated in cuDNN 8.0. Use cudnnSetRNNDescriptor_v8() instead of cudnnSetRNNBiasMode().",
	"cudnnSetRNNDataDescriptor":                                "cudnnSetRNNDataDescriptor initializes a previously created RNN data descriptor object. cudnnSetRNNDataDescriptor data structure is intended to support the unpacked (padded) layout for input and output of extended RNN inference and training functions. A packed (unpadded) layout is also supported for backward compatibility.",
	"cudnnSetRNNDescriptor_v6":                                 "cudnnSetRNNDescriptor_v6 has been deprecated in cuDNN 8.0. Use cudnnSetRNNDescriptor_v8() instead of cudnnSetRNNDescriptor_v6().",
	"cudnnSetRNNDescriptor_v8":                                 "cudnnSetRNNDescriptor_v8 initializes a previously created RNN descriptor object. The RNN descriptor configured by cudnnSetRNNDescriptor_v8() was enhanced to store all information needed to compute the total number of adjustable weights/biases in the RNN model.",
	"cudnnSetRNNMatrixMathType":                                "cudnnSetRNNMatrixMathType has been deprecated in cuDNN 8.0. Use cudnnSetRNNDescriptor_v8() instead of cudnnSetRNNMatrixMathType().",
	"cudnnSetRNNPaddingMode":                                   "cudnnSetRNNPaddingMode has been deprecated in cuDNN 8.0. Use cudnnSetRNNDescriptor_v8() instead of cudnnSetRNNPaddingMode().",
	"cudnnSetRNNProjectionLayers":                              "cudnnSetRNNProjectionLayers has been deprecated in cuDNN 8.0. Use cudnnSetRNNDescriptor_v8() instead of cudnnSetRNNProjectionLayers().",
	"cudnnSetSeqDataDescriptor":                                "For example, to express information that vectors in our sequence data buffer are five elements long, we need to assign dimA[CUDNN_SEQDATA_VECT_DIM]=5 in the dimA[] array.",
	"cudnnAdvTrainVersionCheck":                                "cudnnAdvTrainVersionCheck checks whether the version of the AdvTrain subset of the library is consistent with the other sub-libraries.",
	"cudnnCreateCTCLossDescriptor":                             "cudnnCreateCTCLossDescriptor creates a CTC loss function descriptor.",
	"cudnnCTCLoss":                                             "Input. Handle to a previously created cuDNN context. For more information, see cudnnHandle_t.",
	"cudnnCTCLoss_v8":                                          "Input. Handle to a previously created cuDNN context. For more information, see cudnnHandle_t.",
	"cudnnDestroyCTCLossDescriptor":                            "cudnnDestroyCTCLossDescriptor destroys a CTC loss function descriptor object.",
	"cudnnFindRNNBackwardDataAlgorithmEx":                      "cudnnFindRNNBackwardDataAlgorithmEx attempts all available cuDNN algorithms for cudnnRNNBackwardData(), using user-allocated GPU memory. It outputs the parameters that influence the performance of the algorithm to a user-allocated array of cudnnAlgorithmPerformance_t. These parameter metrics are written in sorted fashion where the first element has the lowest compute time.",
	"cudnnFindRNNBackwardWeightsAlgorithmEx":                   "cudnnFindRNNBackwardWeightsAlgorithmEx attempts all available cuDNN algorithms for cudnnRNNBackwardWeights(), using user-allocated GPU memory. It outputs the parameters that influence the performance of the algorithm to a user-allocated array of cudnnAlgorithmPerformance_t. These parameter metrics are written in sorted fashion where the first element has the lowest compute time.",
	"cudnnFindRNNForwardTrainingAlgorithmEx":                   "cudnnFindRNNForwardTrainingAlgorithmEx attempts all available cuDNN algorithms for cudnnRNNForwardTraining(), using user-allocated GPU memory. It outputs the parameters that influence the performance of the algorithm to a user-allocated array of cudnnAlgorithmPerformance_t. These parameter metrics are written in sorted fashion where the first element has the lowest compute time.",
	"cudnnGetCTCLossDescriptor":                                "cudnnGetCTCLossDescriptor returns the configuration of the passed CTC loss function descriptor.",
	"cudnnGetCTCLossDescriptorEx":                              "cudnnGetCTCLossDescriptorEx returns the configuration of the passed CTC loss function descriptor.",
	"cudnnGetCTCLossDescriptor_v8":                             "cudnnGetCTCLossDescriptor_v8 returns the configuration of the passed CTC loss function descriptor.",
	"cudnnGetCTCLossWorkspaceSize":                             "cudnnGetCTCLossWorkspaceSize returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnCTCLoss() with the specified algorithm. The workspace allocated will then be passed to the routine cudnnCTCLoss().",
	"cudnnGetCTCLossWorkspaceSize_v8":                          "cudnnGetCTCLossWorkspaceSize_v8 returns the amount of GPU memory workspace the user needs to allocate to be able to call cudnnCTCLoss_v8() with the specified algorithm. The workspace allocated will then be passed to the routine cudnnCTCLoss_v8().",
	"cudnnGetRNNTrainingReserveSize":                           "cudnnGetRNNTrainingReserveSize has been deprecated in cuDNN 8.0. Use cudnnGetRNNTempSpaceSizes() instead of cudnnGetRNNWorkspaceSize().",
	"cudnnMultiHeadAttnBackwardData":                           "cudnnMultiHeadAttnBackwardData computes exact, first-order derivatives of the multi-head attention block with respect to its inputs: Q, K, V. If y=F(x) is a vector-valued function that represents the multi-head attention layer and it takes some vector x   n as an input (with all other parameters and inputs constant), and outputs vector y   m , then cudnnMultiHeadAttnBackwardData() computes the result of  y i /  x j T  out where  out is the m  1 gradient of the loss function with respect to multi-head attention outputs. The  out gradient is back propagated through prior layers of the deep learning model.  y i /  x j is the m  n Jacobian matrix of F(x). The input is supplied via the dout argument and gradient results for Q, K, V are written to the dqueries, dkeys, and dvalues buffers.",
	"cudnnMultiHeadAttnBackwardWeights":                        "cudnnMultiHeadAttnBackwardWeights computes exact, first-order derivatives of the multi-head attention block with respect to its trainable parameters: projection weights and projection biases. If y=F(w) is a vector-valued function that represents the multi-head attention layer and it takes some vector x   n of flatten weights or biases as an input (with all other parameters and inputs fixed), and outputs vector y   m , then cudnnMultiHeadAttnBackwardWeights() computes the result of  y i /  x j T  out where  out is the m  1 gradient of the loss function with respect to multi-head attention outputs. The  out gradient is back propagated through prior layers of the deep learning model.  y i /  x j is the m  n Jacobian matrix of F(w). The  out input is supplied via the dout argument.",
	"cudnnRNNBackwardData":                                     "cudnnRNNBackwardData has been deprecated in cuDNN 8.0. Use cudnnRNNBackwardData_v8() instead of cudnnRNNBackwardData().",
	"cudnnRNNBackwardData_v8":                                  "cudnnRNNBackwardData_v8 computes exact, first-order derivatives of the RNN model with respect to its inputs: x, hx and for the LSTM cell typealsocx. If o = [y, hy, cy] = F(x, hx, cx) = F(z) is a vector-valued function that represents the entire RNN model and it takes vectors x(for all time-steps) and vectors hx, cx (for all layers) as inputs, concatenated into z   n (network weights and biases are assumed constant), and outputs vectors y, hy, cy concatenated into a vector o   m , then cudnnRNNBackwardData_v8() computes the result of  o i /  z j T  out where  out is the m  1 gradient of the loss function with respect to all RNN outputs. The  out gradient is back propagated through prior layers of the deep learning model, starting from the model output.  o i /  z j is the m  n Jacobian matrix of F(z). The  out input is supplied via the dy, dhy, and dcy arguments and gradient results  o i /  z j T  out are written to the dx, dhx, and dcx buffers.",
	"cudnnRNNBackwardDataEx":                                   "cudnnRNNBackwardDataEx has been deprecated in cuDNN 8.0. Use cudnnRNNBackwardData_v8 instead of cudnnRNNBackwardDataEx().",
	"cudnnRNNBackwardWeights":                                  "cudnnRNNBackwardWeights has been deprecated in cuDNN 8.0. Use cudnnRNNBackwardWeights_v8() instead of cudnnRNNBackwardWeights().",
	"cudnnRNNBackwardWeights_v8":                               "cudnnRNNBackwardWeights_v8 computes exact, first-order derivatives of the RNN model with respect to all trainable parameters: weights and biases. If o = [y, hy, cy] = F(w) is a vector-valued function that represents the multi-layer RNN model and it takes some vector w   n of `flatten` weights or biases as input (with all other data inputs constant), and outputs vector o   m , then cudnnRNNBackwardWeights_v8() computes the result of  o i /  w j T  out where  out is the m  1 gradient of the loss function with respect to all RNN outputs. The  out gradient is back propagated through prior layers of the deep learning model, starting from the model output.  o i /  w j is the m  n Jacobian matrix of F(w). The  out input is supplied via the dy, dhy, and dcy arguments in the cudnnRNNBackwardData_v8() function.",
	"cudnnRNNBackwardWeightsEx":                                "cudnnRNNBackwardWeightsEx has been deprecated in cuDNN 8.0. Use cudnnRNNBackwardWeights_v8() instead of cudnnRNNBackwardWeightsEX().",
	"cudnnRNNForwardTraining":                                  "Use cudnnRNNForward() instead of cudnnRNNForwardTraining().",
	"cudnnRNNForwardTrainingEx":                                "cudnnRNNForwardTrainingEx has been deprecated starting in cuDNN 8.0. Use cudnnRNNForward() instead of cudnnRNNForwardTrainingEx().",
	"cudnnSetCTCLossDescriptor":                                "cudnnSetCTCLossDescriptor sets a CTC loss function descriptor. See also the extended version cudnnSetCTCLossDescriptorEx() to set the input normalization mode.",
	"cudnnSetCTCLossDescriptorEx":                              "cudnnSetCTCLossDescriptorEx is an extension of cudnnSetCTCLossDescriptor(). cudnnSetCTCLossDescriptorEx provides an additional interface normMode to set the input normalization mode for the CTC loss function, and gradMode to control the NaN propagation type.",
	"cudnnSetCTCLossDescriptor_v8":                             "Many CTC API functions are updated in cuDNN version 8.0.0 to support CUDA graphs. In order to do so, a new parameter is needed, maxLabelLength. Now that label and input data are assumed to be in GPU memory, this information is not otherwise readily available.",
}
